# ìµœì¢… ë§Œí™” ë²ˆì—­ íŒŒì´í”„ë¼ì¸ â€” Production-Ready

> **138ê°œ ê°œì„ ì‚¬í•­**ì„ ëª¨ë‘ í¬í•¨í•œ ì™„ì „í•œ ë¬¸ì„œ

## ğŸ“Š íŒŒì´í”„ë¼ì¸ í†µê³„

| Stage | ê°œì„ ì‚¬í•­ |
|-------|----------|
| PRE-PROCESSING | 15ê°œ |
| STAGE â‘  | 12ê°œ |
| GAP-A | 10ê°œ |
| STAGE â‘¡ | 14ê°œ |
| GAP-B | 12ê°œ |
| STAGE â‘¢ | 15ê°œ |
| GAP-C | 10ê°œ |
| STAGE â‘£ | 18ê°œ |
| POST | 3ê°œ |
| **TOTAL** | **138ê°œ** |

---

## PRE-PROCESSING

### ì••ì¶•ëœ ë§Œí™” íŒŒì¼ ì²˜ë¦¬ (CBZ/CBR)

**ìš°ì„ ìˆœìœ„**: ğŸ”´ CRITICAL

**êµ¬í˜„ ì½”ë“œ**:

```python
import zipfile, rarfile, re

def natural_sort_key(s):
    return [int(t) if t.isdigit() else t.lower() for t in re.split('([0-9]+)', s)]

def extract_manga_archive(file_path):
    if file_path.endswith('.cbz') or file_path.endswith('.zip'):
        with zipfile.ZipFile(file_path, 'r') as z:
            files = []
            for info in z.infolist():
                try:
                    name = info.filename
                except:
                    name = info.filename.encode('cp437').decode('utf-8', errors='ignore')
                files.append((name, z.read(info)))
    elif file_path.endswith('.cbr'):
        with rarfile.RarFile(file_path) as r:
            files = [(info.filename, r.read(info)) for info in r.infolist()]
    
    files.sort(key=lambda x: natural_sort_key(x[0]))
    return files
```

### PDF ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨ (ë²¡í„°/í…ìŠ¤íŠ¸ ë ˆì´ì–´)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
import fitz

def extract_images_from_pdf(pdf_path, dpi=300):
    doc = fitz.open(pdf_path)
    images = []
    for page_num in range(len(doc)):
        page = doc[page_num]
        mat = fitz.Matrix(dpi / 72, dpi / 72)
        pix = page.get_pixmap(matrix=mat, alpha=False)
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        images.append(img)
    return images
```

### ì—¬ëŸ¬ ì´ë¯¸ì§€ í˜•ì‹ í˜¼ì¬ (JPEG/PNG/WebP)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**í•´ê²°ì±…**: â‘  Pillow ìµœì‹  ë²„ì „ â†’ â‘¡ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ RGBë¡œ í†µì¼ (alpha channel ì œê±° í›„ í°ìƒ‰ ë°°ê²½ í•©ì„±)

**êµ¬í˜„ ì½”ë“œ**:

```python
from PIL import Image

def load_and_normalize_image(file_path):
    img = Image.open(file_path)
    if img.mode == 'RGBA':
        bg = Image.new('RGB', img.size, (255, 255, 255))
        bg.paste(img, mask=img.split()[3])
        img = bg
    elif img.mode != 'RGB':
        img = img.convert('RGB')
    return img
```

### ì´ì¤‘í˜ì´ì§€(spread) ë¶„í•  ì˜¤ë¥˜

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
import cv2, numpy as np

def detect_double_page_gutter(img):
    h, w = img.shape[:2]
    center_strip = img[:, int(w*0.4):int(w*0.6)]
    gray = cv2.cvtColor(center_strip, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150)
    vertical_edges = np.sum(edges, axis=0)
    gutter_x = np.argmax(vertical_edges) + int(w*0.4)
    return gutter_x if vertical_edges.max() / edges.size > 0.1 else w // 2

def split_double_page(img):
    h, w = img.shape[:2]
    if w / h < 1.7: return [img]
    gutter_x = detect_double_page_gutter(img)
    center = img[:, gutter_x-50:gutter_x+50]
    if has_important_content(center): return [img]
    return [img[:, :gutter_x], img[:, gutter_x:]]
```

### í‘œì§€Â·ì†í‘œì§€Â·ê´‘ê³  í˜ì´ì§€ ì œê±°

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
def classify_page_type(img, page_num, total):
    if page_num < 3 or page_num >= total - 3:
        text_ratio = detect_text_area_ratio(img)
        if text_ratio < 0.1: return "cover"
    text_ratio = detect_text_area_ratio(img)
    if text_ratio > 0.3: return "ad"
    return "content"
```

### í˜ì´ì§€ ë°©í–¥ ì˜¤ë¥˜ (íšŒì „ëœ í˜ì´ì§€)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**í•´ê²°ì±…**: â‘  Tesseract OSDë¡œ ë°©í–¥ ê°ì§€ â†’ â‘¡ ìë™ íšŒì „ í›„ confidence ë¹„êµ â†’ â‘¢ ë†’ì€ ìª½ ì„ íƒ

**êµ¬í˜„ ì½”ë“œ**:

```python
import pytesseract

def detect_and_fix_orientation(img):
    try:
        osd = pytesseract.image_to_osd(img)
        angle = int(re.search(r'Rotate: (\\d+)', osd).group(1))
        if angle != 0:
            img = img.rotate(angle, expand=True)
    except:
        pass
    return img
```

### í˜ì´ì§€ ìˆœì„œ ê²€ì¦ (ë©”íƒ€ë°ì´í„° ë¶ˆì‹ )

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
import imagehash

def verify_page_order(pages):
    for i in range(len(pages) - 1):
        h1 = imagehash.average_hash(pages[i])
        h2 = imagehash.average_hash(pages[i+1])
        similarity = 1 - (h1 - h2) / 64.0
        if similarity < 0.3:
            print(f"Warning: Pages {i} and {i+1} are very different")
```

### ì €í•´ìƒë„ ìŠ¤ìº” (< 150 DPI)

**ìš°ì„ ìˆœìœ„**: ğŸ”´ CRITICAL

**êµ¬í˜„ ì½”ë“œ**:

```python
import cv2
from PIL import Image, ImageFilter

def upscale_low_resolution(img, target_dpi=300):
    current_dpi = estimate_dpi(img)
    if current_dpi >= target_dpi: return img
    
    scale = target_dpi / current_dpi
    h, w = img.shape[:2]
    
    if current_dpi < 150:
        print(f"Warning: Very low DPI ({current_dpi})")
        add_to_manual_review("low_dpi", img)
    
    img_pil = Image.fromarray(img)
    img_pil = img_pil.resize((int(w*scale), int(h*scale)), Image.BICUBIC)
    img_pil = img_pil.filter(ImageFilter.UnsharpMask(radius=2, percent=150))
    return np.array(img_pil)
```

### ë°°ê²½ ë…¸ì´ì¦ˆ (ì¢…ì´ ì§ˆê°, ì–¼ë£©, ê·¸ë¦¼ì)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
import cv2, numpy as np

def remove_background_noise(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    kernel = np.ones((3, 3), np.uint8)
    opened = cv2.morphologyEx(blurred, cv2.MORPH_OPEN, kernel)
    shadow_free = cv2.divide(gray, blurred, scale=255)
    _, normalized = cv2.threshold(shadow_free, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return normalized
```

### JPEG ì••ì¶• ì•„í‹°íŒ©íŠ¸ (ë¸”ë¡ ë…¸ì´ì¦ˆ)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**í•´ê²°ì±…**: â‘  Non-local means denoising â†’ â‘¡ Bilateral filter (edge ë³´ì¡´) â†’ â‘¢ ê°€ëŠ¥í•˜ë©´ PNG ìš”ì²­

**êµ¬í˜„ ì½”ë“œ**:

```python
import cv2

def remove_jpeg_artifacts(img):
    denoised = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)
    smooth = cv2.bilateralFilter(denoised, 9, 75, 75)
    return smooth
```

### ì´ë¯¸ì§€ í¬ê¸° ë¶ˆì¼ì¹˜ (í•´ìƒë„ ì œê°ê°)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
def normalize_page_sizes(pages):
    max_height = max(p.shape[0] for p in pages)
    normalized = []
    for page in pages:
        h, w = page.shape[:2]
        if h < max_height:
            scale = max_height / h
            new_w = int(w * scale)
            resized = cv2.resize(page, (new_w, max_height))
            normalized.append(resized)
        else:
            normalized.append(page)
    return normalized
```

### ìƒ‰ìƒ ë°¸ëŸ°ìŠ¤ ë¶ˆê· í˜• (ìŠ¤ìº”ë§ˆë‹¤ ìƒ‰ê° ë‹¤ë¦„)

**ìš°ì„ ìˆœìœ„**: âšª LOW

**í•´ê²°ì±…**: â‘  ìƒ‰ìƒ íˆìŠ¤í† ê·¸ë¨ ë¶„ì„ â†’ â‘¡ í‰ê·  ë°ê¸°Â·ëŒ€ë¹„ ì •ê·œí™” â†’ â‘¢ White balance ìë™ ì¡°ì •

**êµ¬í˜„ ì½”ë“œ**:

```python
import cv2

def normalize_color_balance(img):
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    l = clahe.apply(l)
    lab = cv2.merge([l, a, b])
    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
```

### ì»¬ëŸ¬ vs í‘ë°± ë§Œí™” ìë™ ê°ì§€

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
import numpy as np

def detect_color_mode(img):
    std_r, std_g, std_b = [np.std(img[:,:,i]) for i in range(3)]
    if std_r < 10 and std_g < 10 and std_b < 10:
        return "grayscale"
    return "color"
```

### í‘ë°± ë°˜ì „ í˜ì´ì§€ (ë„¤ê±°í‹°ë¸Œ)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**í•´ê²°ì±…**: â‘  í˜ì´ì§€ í‰ê·  ë°ê¸° ê³„ì‚° â†’ â‘¡ < 128ì´ë©´ ë°˜ì „ â†’ â‘¢ ìƒ‰ìƒ ë°˜ì „ (255 - pixel) í›„ OCR

**êµ¬í˜„ ì½”ë“œ**:

```python
def detect_and_fix_inverted_page(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    mean = np.mean(gray)
    if mean < 128:
        img = 255 - img
    return img
```

### íˆ¬ëª… ë°°ê²½ ì²˜ë¦¬ (PNG alpha)

**ìš°ì„ ìˆœìœ„**: âšª LOW

**í•´ê²°ì±…**: ì´ë¯¸ pre-3ì—ì„œ ì²˜ë¦¬ (RGBA â†’ RGB í°ìƒ‰ ë°°ê²½ í•©ì„±)

**êµ¬í˜„ ì½”ë“œ**:

```python
# ì´ë¯¸ pre-3 load_and_normalize_image()ì—ì„œ êµ¬í˜„ë¨
```

## STAGE â‘  â€” ì˜ì—­ ê°ì§€

### ë°°ê²½ ì—†ëŠ” ì¹¸ (borderless panels)

**ìš°ì„ ìˆœìœ„**: ğŸ”´ CRITICAL

**êµ¬í˜„ ì½”ë“œ**:

```python
from sklearn.cluster import DBSCAN
import numpy as np

def detect_panels_by_text_clustering(text_regions):
    if len(text_regions) == 0: return []
    centers = np.array([[r.x + r.width/2, r.y + r.height/2] for r in text_regions])
    clustering = DBSCAN(eps=200, min_samples=1).fit(centers)
    labels = clustering.labels_
    
    panels = []
    for label in set(labels):
        if label == -1: continue
        cluster = [r for i, r in enumerate(text_regions) if labels[i] == label]
        min_x, min_y = min(r.x for r in cluster), min(r.y for r in cluster)
        max_x, max_y = max(r.x + r.width for r in cluster), max(r.y + r.height for r in cluster)
        panels.append({"x": min_x, "y": min_y, "width": max_x - min_x, "height": max_y - min_y})
    return panels
```

### ê²¹ì¹˜ëŠ” ì¹¸ (overlapping panels)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
def filter_overlapping_panels(panels):
    filtered = []
    for i, panel_i in enumerate(panels):
        is_contained = False
        for j, panel_j in enumerate(panels):
            if i == j: continue
            if (panel_i.x >= panel_j.x and panel_i.y >= panel_j.y and
                panel_i.x + panel_i.width <= panel_j.x + panel_j.width and
                panel_i.y + panel_i.height <= panel_j.y + panel_j.height):
                is_contained = True
                break
        if not is_contained: filtered.append(panel_i)
    return filtered
```

### ë¹„ì •í˜• ì¹¸ (irregular shaped panels)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**í•´ê²°ì±…**: â‘  YOLO bbox í›„ contour detectionìœ¼ë¡œ ì •í™•í•œ ê²½ê³„ ì¶”ì¶œ â†’ â‘¡ mask ìƒì„±í•´ ì¹¸ ë‚´ë¶€ë§Œ ì¸ì •

**êµ¬í˜„ ì½”ë“œ**:

```python
import cv2

def refine_panel_boundary(img, bbox):
    x, y, w, h = bbox
    roi = img[y:y+h, x:x+w]
    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150)
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if len(contours) == 0: return bbox
    largest = max(contours, key=cv2.contourArea)
    mask = np.zeros_like(gray)
    cv2.drawContours(mask, [largest], -1, 255, -1)
    return {"bbox": bbox, "mask": mask}
```

### splash page vs ë‹¨ì¼ ì¹¸ êµ¬ë¶„

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**í•´ê²°ì±…**: â‘  ì¹¸=1ì¼ ë•Œ í…ìŠ¤íŠ¸ ë°€ë„ ê³„ì‚° â†’ â‘¡ 5% ì´ìƒì´ë©´ ë‹¨ì¼ ì¹¸ â†’ â‘¢ 5% ë¯¸ë§Œì´ë©´ splash

**êµ¬í˜„ ì½”ë“œ**:

```python
def classify_single_panel_page(img, panel, text_regions):
    page_area = img.shape[0] * img.shape[1]
    text_area = sum(r.width * r.height for r in text_regions)
    density = text_area / page_area
    return "single_panel" if density > 0.05 else "splash"
```

### íš¨ê³¼ìŒ(SFX) ê°ì§€ ì‹¤íŒ¨ (ì•„í‹°ìŠ¤í‹± í°íŠ¸)

**ìš°ì„ ìˆœìœ„**: ğŸ”´ CRITICAL

**êµ¬í˜„ ì½”ë“œ**:

```python
def detect_sfx_with_low_confidence(img, model, conf=0.3):
    results = model(img, conf=conf)
    sfx = []
    for det in results.xyxy[0]:
        x1, y1, x2, y2, conf, cls = det
        if cls == 2 and conf > 0.3:  # SFX class
            sfx.append({"x": int(x1), "y": int(y1), "width": int(x2-x1), "height": int(y2-y1)})
    return sfx
```

### í›„ë¦¬ê°€ë‚˜(furigana) ê°ì§€ ì‹¤íŒ¨

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**í•´ê²°ì±…**: â‘  í…ìŠ¤íŠ¸ ê°ì§€ í›„ 'ìƒë‹¨ì— ì‘ì€ í…ìŠ¤íŠ¸' ì¶”ê°€ ê²€ì‚¬ â†’ â‘¡ ëŒ€í™” bbox ìœ„ 30px ë³„ë„ OCR

**êµ¬í˜„ ì½”ë“œ**:

```python
def detect_furigana_above_dialogue(img, dialogue_bbox):
    x, y, w, h = dialogue_bbox
    if y < 30: return None
    furigana_roi = img[max(0, y-30):y, x:x+w]
    gray = cv2.cvtColor(furigana_roi, cv2.COLOR_BGR2GRAY)
    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    text_ratio = np.sum(binary > 0) / binary.size
    if text_ratio > 0.1:
        return {"x": x, "y": max(0, y-30), "width": w, "height": 30, "type": "furigana"}
    return None
```

### ë°°ê²½ê³¼ ê²¹ì¹œ í…ìŠ¤íŠ¸ (ë³µì¡í•œ ë°°ê²½)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
def filter_false_positive(img, candidates):
    valid = []
    for c in candidates:
        roi = img[c.y:c.y+c.h, c.x:c.x+c.w]
        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.sum(edges > 0) / edges.size
        if edge_density > 0.4:  # ë°°ê²½ì¼ ê°€ëŠ¥ì„±
            text = ocr.read(roi)
            if text.confidence < 0.5: continue
        valid.append(c)
    return valid
```

### í…ìŠ¤íŠ¸ ì˜ì—­ ê²½ê³„ ë¶ˆì™„ì „ (ì¼ë¶€ë§Œ ê°ì§€)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**í•´ê²°ì±…**: â‘  bbox ìë™ í™•ì¥ (padding +10px) â†’ â‘¡ morphological dilation â†’ â‘¢ contourë¡œ ì¬ê³„ì‚°

**êµ¬í˜„ ì½”ë“œ**:

```python
def expand_text_bbox(bbox, padding=10):
    x, y, w, h = bbox
    return {
        "x": max(0, x - padding),
        "y": max(0, y - padding),
        "width": w + 2 * padding,
        "height": h + 2 * padding
    }
```

### ì„¸ë¡œ ìŠ¤í¬ë¡¤ ë§Œí™”(webtoon) ì½ê¸° ìˆœì„œ

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
def determine_reading_mode(img):
    h, w = img.shape[:2]
    return "vertical_scroll" if h / w > 2.0 else "horizontal"

def sort_panels(panels, img):
    mode = determine_reading_mode(img)
    if mode == "vertical_scroll":
        return sorted(panels, key=lambda p: p.y)
    return sorted(panels, key=lambda p: (p.y, -p.x))
```

### ê°™ì€ í–‰(row) íŒë‹¨ ì„ê³„ê°’

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**í•´ê²°ì±…**: â‘  í˜ì´ì§€ ë†’ì´ ë¹„ìœ¨ë¡œ ì„¤ì • (height Ã— 0.05) â†’ â‘¡ ë˜ëŠ” ì¹¸ ë†’ì´ í‰ê· ê°’

**êµ¬í˜„ ì½”ë“œ**:

```python
def group_panels_by_row(panels, img):
    h, w = img.shape[:2]
    threshold = h * 0.05
    rows = []
    for p in sorted(panels, key=lambda p: p.y):
        if not rows or abs(p.y - rows[-1][0].y) > threshold:
            rows.append([p])
        else:
            rows[-1].append(p)
    for row in rows: row.sort(key=lambda p: -p.x)
    return [p for row in rows for p in row]
```

### ëŒ€ê°ì„  ë ˆì´ì•„ì›ƒ (diagonal layout)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**í•´ê²°ì±…**: â‘  ì¹¸ ê°„ ì‹œê°ì  ì—°ê²°ì„± ë¶„ì„ (ê°€ì¥ ê°€ê¹Œìš´ ì´ì›ƒ) â†’ â‘¡ graph traversalë¡œ ìˆœì„œ ê²°ì •

**êµ¬í˜„ ì½”ë“œ**:

```python
from scipy.spatial import distance

def sort_by_visual_flow(panels):
    if len(panels) == 0: return []
    centers = [(p.x + p.width/2, p.y + p.height/2) for p in panels]
    sorted_panels = [panels[0]]
    remaining = list(range(1, len(panels)))
    
    while remaining:
        last_center = centers[panels.index(sorted_panels[-1])]
        distances = [distance.euclidean(last_center, centers[i]) for i in remaining]
        nearest = remaining[np.argmin(distances)]
        sorted_panels.append(panels[nearest])
        remaining.remove(nearest)
    return sorted_panels
```

### ì¹¸ ë‚´ë¶€ í…ìŠ¤íŠ¸ ì½ê¸° ìˆœì„œ (intra-panel)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**í•´ê²°ì±…**: â‘  ì¹¸ ë‚´ë¶€ í…ìŠ¤íŠ¸ë¥¼ ì½ê¸° ìˆœì„œ ì •ë ¬ â†’ â‘¡ íƒ€ì…ë³„ ìš°ì„ ìˆœìœ„ (ë‚˜ë ˆì´ì…˜ 0, ëŒ€í™” 1, SFX 2)

**êµ¬í˜„ ì½”ë“œ**:

```python
def sort_text_within_panel(text_regions):
    priority = {"narration": 0, "dialogue": 1, "SFX": 2}
    return sorted(text_regions, key=lambda r: (priority.get(r.type, 1), r.y, -r.x))
```

## GAP-A â€” ë§í’ì„  ê²½ê³„

### ë§í’ì„  ì—†ëŠ” í…ìŠ¤íŠ¸ (floating text)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
def get_text_placement_area(text_region, img):
    text_type = text_region.type
    if text_type in ['dialogue']:
        balloon = detect_balloon_around_text(img, text_region)
        return balloon.interior_area if balloon else text_region.bbox
    elif text_type in ['narration', 'thought']:
        return expand_bbox(text_region.bbox, margin=10)
    else:  # SFX
        return None  # ììœ  ë°°ì¹˜
```

### íˆ¬ëª…/ì—°í•œ ë§í’ì„  (low contrast)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
def detect_balloon_adaptive(img, text_bbox):
    x, y, w, h = text_bbox
    margin = 50
    roi = img[max(0,y-margin):min(img.shape[0],y+h+margin),
              max(0,x-margin):min(img.shape[1],x+w+margin)]
    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    
    for threshold in [50, 100, 150]:
        edges = cv2.Canny(gray, threshold, threshold * 2)
        kernel = np.ones((5,5), np.uint8)
        closed = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)
        contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for cnt in contours:
            if cv2.contourArea(cnt) > 100 and point_in_contour((x+w//2, y+h//2), cnt):
                return cnt
    return None
```

### ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ê³µìœ  ë§í’ì„  (multi-text balloon)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
def deduplicate_balloons(balloons, iou_threshold=0.8):
    unique = []
    for balloon in balloons:
        is_duplicate = False
        for unique_balloon in unique:
            iou = calculate_iou(balloon.bbox, unique_balloon.bbox)
            if iou > iou_threshold:
                is_duplicate = True
                unique_balloon.texts.append(balloon.texts[0])
                break
        if not is_duplicate:
            unique.append(balloon)
    return unique
```

### ë§í’ì„  íƒ€ì… ë¶„ë¥˜ (ì¼ë°˜/ìƒê°/ì™¸ì¹¨/ì†ì‚­ì„)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
def classify_balloon_type(contour, edges):
    area = cv2.contourArea(contour)
    perimeter = cv2.arcLength(contour, True)
    circularity = 4 * np.pi * area / (perimeter ** 2) if perimeter > 0 else 0
    hull = cv2.convexHull(contour)
    hull_area = cv2.contourArea(hull)
    convexity = area / hull_area if hull_area > 0 else 0
    
    if convexity < 0.85:
        return "thought"
    elif circularity < 0.6:
        return "shout"
    else:
        return "normal"
```

### ë§í’ì„  vs íš¨ê³¼ì„  êµ¬ë¶„

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
def is_balloon_not_effect_line(contour):
    area = cv2.contourArea(contour)
    if area < 100:
        return False
    start = contour[0][0]
    end = contour[-1][0]
    distance = np.linalg.norm(start - end)
    perimeter = cv2.arcLength(contour, True)
    if distance / perimeter > 0.1:
        return False  # ì—´ë¦° ì„ 
    return True
```

### ì—°ê²°ëœ ë§í’ì„  (connected balloons)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
def split_connected_balloons(contour, img):
    mask = np.zeros(img.shape[:2], dtype=np.uint8)
    cv2.drawContours(mask, [contour], -1, 255, -1)
    dist = cv2.distanceTransform(mask, cv2.DIST_L2, 5)
    threshold = dist.max() * 0.3
    _, waist = cv2.threshold(dist, threshold, 255, cv2.THRESH_BINARY_INV)
    waist = waist.astype(np.uint8)
    if np.sum(waist > 0) > 0:
        mask_without_waist = mask - waist
        separated, _ = cv2.findContours(mask_without_waist, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        return separated
    return [contour]
```

### ë§í’ì„  ê¼¬ë¦¬ ì†ìƒ (tail damage)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
def detect_balloon_tail(contour):
    hull = cv2.convexHull(contour, returnPoints=False)
    defects = cv2.convexityDefects(contour, hull)
    if defects is None:
        return None
    M = cv2.moments(contour)
    cx = int(M['m10'] / M['m00']) if M['m00'] != 0 else 0
    cy = int(M['m01'] / M['m00']) if M['m00'] != 0 else 0
    
    max_defect = None
    max_depth = 0
    for i in range(defects.shape[0]):
        s, e, f, d = defects[i, 0]
        far = tuple(contour[f][0])
        if d > max_depth:
            max_depth = d
            max_defect = far
    return max_defect
```

### ë§í’ì„  ë‚´ë¶€ ë§ˆì§„ ê³„ì‚° (interior margin)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
def calculate_adaptive_margin(balloon_area):
    if balloon_area < 5000:
        return 2
    elif balloon_area < 20000:
        return 5
    else:
        return 10

def apply_margin(balloon_contour):
    area = cv2.contourArea(balloon_contour)
    margin = calculate_adaptive_margin(area)
    mask = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)
    cv2.drawContours(mask, [balloon_contour], -1, 255, -1)
    kernel = np.ones((margin*2, margin*2), np.uint8)
    eroded = cv2.erode(mask, kernel, iterations=1)
    return eroded
```

### ë¶ˆê·œì¹™ ë§í’ì„  ë‚´ë¶€ ìµœëŒ€ ì‚¬ê°í˜•

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
def find_inscribed_rectangle(balloon_contour, img_shape):
    mask = np.zeros(img_shape[:2], dtype=np.uint8)
    cv2.drawContours(mask, [balloon_contour], -1, 255, -1)
    dist = cv2.distanceTransform(mask, cv2.DIST_L2, 5)
    _, max_dist, _, max_loc = cv2.minMaxLoc(dist)
    cx, cy = max_loc
    radius = int(max_dist)
    rect_size = int(radius * 1.414)
    return {"x": cx - rect_size//2, "y": cy - rect_size//2, "width": rect_size, "height": rect_size}
```

### ë§í’ì„  ê²½ê³„ì™€ íŒ¨ë„ ê²½ê³„ ì¶©ëŒ

**ìš°ì„ ìˆœìœ„**: âšª LOW

**êµ¬í˜„ ì½”ë“œ**:

```python
def clip_balloon_to_panel(balloon_contour, panel_bbox):
    x, y, w, h = panel_bbox
    clipped_points = []
    for point in balloon_contour:
        px, py = point[0]
        px_clipped = max(x, min(x + w, px))
        py_clipped = max(y, min(y + h, py))
        clipped_points.append([[px_clipped, py_clipped]])
    return np.array(clipped_points, dtype=np.int32)
```

## STAGE â‘¡ â€” OCR

### ì €í•´ìƒë„Â·ë¸”ëŸ¬ ì´ë¯¸ì§€ (low quality input)

**ìš°ì„ ìˆœìœ„**: ğŸ”´ CRITICAL

**êµ¬í˜„ ì½”ë“œ**:

```python
def enhance_text_region(text_roi):
    h, w = text_roi.shape[:2]
    if h < 20 or w < 20:
        scale = max(2, 20 / min(h, w))
        text_roi = cv2.resize(text_roi, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)
        text_roi = cv2.filter2D(text_roi, -1, sharpen_kernel)
    return text_roi
```

### ìœ ì‚¬ ê¸€ì í˜¼ë™ (similar character confusion)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
import MeCab
mecab = MeCab.Tagger()

def validate_ocr_with_context(text):
    parsed = mecab.parse(text)
    unk_count = parsed.count('UNK')
    if unk_count / len(text.split()) > 0.3:
        alternatives = generate_similar_char_alternatives(text)
        for alt in alternatives:
            if mecab.parse(alt).count('UNK') < unk_count:
                return alt
    return text
```

### ì†ê¸€ì”¨Â·ì•„í‹°ìŠ¤í‹± í°íŠ¸ (stylized fonts)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
sfx_dictionary = {'ãƒ‰ã‚­ãƒ‰ã‚­': 'heartbeat', 'ã‚´ã‚´ã‚´': 'menacing', 'ãƒ‰ãƒ‰ãƒ‰': 'rumble'}

def ocr_sfx_with_fallbacks(sfx_img):
    result = manga_ocr.readtext(sfx_img)
    if result.confidence > 0.5:
        return result.text
    for sfx_text in sfx_dictionary:
        if image_similarity(sfx_img, render_text(sfx_text)) > 0.7:
            return sfx_text
    return ask_llm_to_recognize_sfx(sfx_img)
```

### í…ìŠ¤íŠ¸ ë°°ê²½ ê°„ì„­ (background interference)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
def remove_background_from_text(text_roi):
    gray = cv2.cvtColor(text_roi, cv2.COLOR_BGR2GRAY)
    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
    text_on_white = np.ones_like(text_roi) * 255
    text_on_white[binary == 0] = 0
    return text_on_white
```

### ê¸€ì ê²¹ì¹¨Â·ì—°ê²° (overlapping/connected characters)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
def separate_connected_chars(text_img):
    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    kernel = np.ones((3,3), np.uint8)
    opened = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
    dist = cv2.distanceTransform(opened, cv2.DIST_L2, 5)
    _, sure_fg = cv2.threshold(dist, 0.5 * dist.max(), 255, 0)
    # watershedë¡œ ê¸€ì ë¶„ë¦¬
    return separated_chars
```

### í›„ë¦¬ê°€ë‚˜ ë¶„ë¦¬ ë° ë§¤ì¹­ (furigana)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
def match_furigana_to_kanji(kanji_region, furigana_region):
    kanji_text = ocr(kanji_region.img)
    furigana_text = ocr(furigana_region.img)
    if furigana_region.y + furigana_region.height < kanji_region.y:
        return {"kanji": kanji_text, "furigana": furigana_text, "translate": kanji_text}
    return None
```

### ì„¸ë¡œ ì“°ê¸° í…ìŠ¤íŠ¸ (vertical text orientation)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
def detect_text_orientation(text_roi):
    h, w = text_roi.shape[:2]
    aspect_ratio = w / h
    if aspect_ratio > 2.0:
        return "horizontal"
    elif aspect_ratio < 0.5:
        return "vertical"
    return detect_char_alignment(text_roi)
```

### ì˜ì–´Â·ìˆ«ì í˜¼ì¬ í…ìŠ¤íŠ¸ (mixed language)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
import unicodedata

def normalize_mixed_language_text(text):
    normalized = unicodedata.normalize('NFKC', text)  # ì „ê°â†’ë°˜ê°
    english_words = re.findall(r'[A-Za-z]+', normalized)
    for word in english_words:
        if word.lower() in english_dictionary:
            normalized = normalized.replace(word, word.capitalize())
    return normalized
```

### íŠ¹ìˆ˜ ê¸°í˜¸Â·êµ¬ë‘ì  (special symbols)

**ìš°ì„ ìˆœìœ„**: âšª LOW

**í•´ê²°ì±…**: íŠ¹ìˆ˜ ê¸°í˜¸ëŠ” ìœ ë‹ˆì½”ë“œë¡œ ì •í™•íˆ ì¸ì‹ â†’ ë²ˆì—­ ì‹œ ê¸°í˜¸ëŠ” ë³´ì¡´ â†’ í•œêµ­ì–´ ë²ˆì—­ í›„ì—ë„ ë™ì¼ ê¸°í˜¸ ì‚¬ìš©

**êµ¬í˜„ ì½”ë“œ**:

```python
def preserve_special_symbols(text, translation):
    symbols = re.findall(r'[ï¼ï¼Ÿâ€¦ï½â™¡â™¥â˜…â˜†â€»]', text)
    for symbol in symbols:
        if symbol not in translation:
            translation += symbol
    return translation
```

### ë‹¤êµ­ì–´ ë§Œí™” (multilingual comics)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
from langdetect import detect

def detect_and_ocr_multilingual(text_roi):
    result_ja = manga_ocr.readtext(text_roi)
    result_cn = paddle_ocr.ocr(text_roi, lang='ch')
    result_en = pytesseract.image_to_string(text_roi, lang='eng')
    
    results = [(result_ja.text, result_ja.confidence, 'ja'),
               (result_cn[0][1][0], result_cn[0][1][1], 'zh'),
               (result_en, 0.5, 'en')]
    best = max(results, key=lambda x: x[1])
    return {"text": best[0], "language": best[2]}
```

### íšŒì „ëœ í…ìŠ¤íŠ¸ (rotated text)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
def ocr_with_rotation_correction(text_roi):
    best_result = None
    best_conf = 0
    for angle in [0, 90, 180, 270]:
        rotated = rotate_image(text_roi, angle)
        result = manga_ocr.readtext(rotated)
        if result.confidence > best_conf:
            best_conf = result.confidence
            best_result = result
    return best_result
```

### ì˜¤ë¥¸ìª½â†’ì™¼ìª½ ì“°ê¸° (RTL languages)

**ìš°ì„ ìˆœìœ„**: âšª LOW

**í•´ê²°ì±…**: ì–¸ì–´ ê°ì§€ë¡œ RTL ì–¸ì–´ì¸ì§€ í™•ì¸ â†’ RTLì´ë©´ OCR ê²°ê³¼ë¥¼ ì—­ìˆœìœ¼ë¡œ ì •ë ¬

**êµ¬í˜„ ì½”ë“œ**:

```python
def fix_rtl_text_order(text, language):
    rtl_languages = ['ar', 'he', 'fa']
    if language in rtl_languages:
        words = text.split()
        return ' '.join(reversed(words))
    return text
```

### OCR confidence ì„ê³„ê°’ (confidence threshold)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
def validate_ocr_confidence(ocr_result, text_type):
    thresholds = {"dialogue": 0.7, "narration": 0.8, "SFX": 0.4, "small_text": 0.6}
    threshold = thresholds.get(text_type, 0.6)
    if ocr_result.confidence >= threshold:
        return ocr_result.text
    else:
        add_to_manual_review("low_confidence", ocr_result, text_type)
        return None
```

### OCR í›„ ì–¸ì–´ ëª¨ë¸ ê²€ì¦ (language model validation)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
import MeCab
mecab = MeCab.Tagger()

def validate_with_language_model(ocr_text):
    parsed = mecab.parse(ocr_text)
    lines = parsed.strip().split('\\n')
    total = len(lines) - 1
    unk_count = sum(1 for line in lines if '\\t' in line and line.split('\\t')[1].startswith('UNK'))
    unk_ratio = unk_count / total if total > 0 else 0
    
    if unk_ratio > 0.3:
        return {"valid": False, "reason": f"Too many unknown words: {unk_ratio:.1%}"}
    return {"valid": True}
```

## GAP-B â€” ë²ˆì—­ ì „ì²˜ë¦¬

### ë‹¨ì¼ íŒ¨ë„ ë²ˆì—­ (context loss)

**ìš°ì„ ìˆœìœ„**: ğŸ”´ CRITICAL

**êµ¬í˜„ ì½”ë“œ**:

```python
def translate_page_batch(page_texts):
    context = "\\n".join([f"{i+1}. {text.content}" for i, text in enumerate(page_texts)])
    prompt = f"""ë‹¤ìŒì€ ë§Œí™” í•œ í˜ì´ì§€ì˜ ëª¨ë“  ëŒ€ì‚¬ì…ë‹ˆë‹¤. ì „ì²´ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ë²ˆì—­í•´ì£¼ì„¸ìš”.

{context}

ë²ˆì—­ ê²°ê³¼ë¥¼ ê°™ì€ ë²ˆí˜¸ë¡œ ë°˜í™˜:
"""
    response = llm.complete(prompt)
    translations = parse_numbered_translations(response)
    return translations
```

### ìºë¦­í„° ë°œí™” ìˆœì„œ (speaker tracking)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
def assign_speaker(text, characters):
    if text.balloon and text.balloon.tail:
        nearest_char = find_nearest_character(text.balloon.tail.direction, characters)
        text.speaker = nearest_char
    return text

def create_prompt_with_speakers(page_texts):
    context = []
    for i, text in enumerate(page_texts):
        speaker = text.speaker if text.speaker else "Unknown"
        context.append(f"{i+1}. [{speaker}]: {text.content}")
    return "\\n".join(context)
```

### í˜ì´ì§€ ê°„ context ì—°ê²° (cross-page context)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
def translate_with_prev_context(current_page, previous_page, context_size=3):
    prev_context = []
    if previous_page:
        last_texts = previous_page.texts[-context_size:]
        for text in last_texts:
            prev_context.append(f"[ì´ì „]: {text.content} â†’ {text.translation}")
    
    prompt = f"""ì´ì „ í˜ì´ì§€: {chr(10).join(prev_context)}

í˜„ì¬ í˜ì´ì§€: {chr(10).join([t.content for t in current_page.texts])}

ì´ì „ ëŒ€ì‚¬ë¥¼ ì°¸ê³ í•˜ì—¬ ë²ˆì—­:
"""
    return prompt
```

### ìƒëµëœ ì£¼ì–´ ë³µì› (omitted subject recovery)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
prompt = """ì¼ë³¸ì–´ëŠ” ì£¼ì–´ë¥¼ ìì£¼ ìƒëµí•˜ì§€ë§Œ, í•œêµ­ì–´ ë²ˆì—­ì—ì„œëŠ” ë§¥ë½ìƒ ëª…í™•í•œ ê²½ìš° ì£¼ì–´ë¥¼ ë³µì›í•˜ì„¸ìš”.
ì˜ˆì‹œ: "å¥½ãã§ã™" â†’ ì´ì „ ëŒ€ì‚¬ì—ì„œ Aê°€ Bì— ëŒ€í•´ ë§í•˜ëŠ” ì¤‘ì´ë©´ "Bë¥¼ ì¢‹ì•„í•´ìš”"

ëŒ€ì‚¬: {texts}
"""
```

### ìºë¦­í„° ì´ë¦„ ë¶ˆì¼ì¹˜ (inconsistent names)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
character_name_dict = {}

def extract_character_name(text):
    names = re.findall(r'[ä¸€-é¾¯]{2,4}(?:ã•ã‚“|å›|ã¡ã‚ƒã‚“|æ§˜)?', text)
    for name in names:
        if name not in character_name_dict:
            translated = llm.translate_name(name)
            character_name_dict[name] = translated
    return character_name_dict

def create_prompt_with_dict(texts):
    dict_str = "\\n".join([f"- {ja}: {ko}" for ja, ko in character_name_dict.items()])
    prompt = f"""ìºë¦­í„° ì´ë¦„ ì‚¬ì „: {dict_str}

ìœ„ ì‚¬ì „ì„ ì°¸ê³ í•˜ì—¬ ì´ë¦„ì„ ì¼ê´€ë˜ê²Œ ì‚¬ìš©í•˜ì„¸ìš”.
"""
    return prompt
```

### í˜¸ì¹­Â·ê²½ì–´ ì¼ê´€ì„± (honorifics consistency)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
character_relationships = {
    "ä½è—¤": {"role": "ì„ ë°°", "tone": "formal"},
    "ç”°ä¸­": {"role": "ì¹œêµ¬", "tone": "casual"}
}

def apply_honorifics(name, speaker, listener):
    if listener in character_relationships:
        rel = character_relationships[listener]
        if rel["tone"] == "formal":
            return f"{name} ì”¨" if rel["role"] != "ìƒì‚¬" else f"{name} ë‹˜"
        elif rel["tone"] == "casual":
            return name
    return f"{name} ì”¨"
```

### ì „ë¬¸ ìš©ì–´ ì‚¬ì „ (terminology dictionary)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
terminology_dict = {
    "fantasy": {"é­”æ³•": "ë§ˆë²•", "ã‚¹ã‚­ãƒ«": "ìŠ¤í‚¬", "ãƒ¬ãƒ™ãƒ«": "ë ˆë²¨"},
    "medical": {"æ‰‹è¡“": "ìˆ˜ìˆ ", "ç—‡çŠ¶": "ì¦ìƒ", "è¨ºæ–­": "ì§„ë‹¨"}
}

def create_prompt_with_terminology(texts, genre):
    if genre in terminology_dict:
        terms = terminology_dict[genre]
        term_str = "\\n".join([f"- {ja}: {ko}" for ja, ko in terms.items()])
        prompt = f"""ì¥ë¥´: {genre}. ë‹¤ìŒ ìš©ì–´ë¥¼ ì¼ê´€ë˜ê²Œ ì‚¬ìš©: {term_str}"""
        return prompt
```

### ì¥ë¥´ë³„ ë²ˆì—­ í†¤ (genre-specific tone)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
genre_instructions = {
    "action": "ì§ì„¤ì ì´ê³  ê°•ë ¬í•˜ê²Œ. ì§§ê³  ì„íŒ©íŠ¸ ìˆëŠ” ë¬¸ì¥.",
    "romance": "ê°ì„±ì ì´ê³  ì„¬ì„¸í•˜ê²Œ. ê°ì • í‘œí˜„ì„ í’ë¶€í•˜ê²Œ.",
    "comedy": "ìœ ë¨¸ì™€ ë§ì¥ë‚œì„ ì‚´ë ¤ì„œ.",
    "horror": "ê¸´ì¥ê°ê³¼ ë¶ˆì•ˆê° ìœ ì§€."
}

def create_genre_prompt(texts, genre):
    instruction = genre_instructions.get(genre, "ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­")
    prompt = f"""ì¥ë¥´: {genre}. ë²ˆì—­ í†¤: {instruction}

ëŒ€ì‚¬: {texts}
"""
    return prompt
```

### ëŒ€ìƒ ë…ìì¸µ (target audience)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
audience_instructions = {
    "children": "ì‰½ê³  êµìœ¡ì ì¸ í‘œí˜„. í­ë ¥ì Â·ì„ ì •ì  í‘œí˜„ ìˆœí™”.",
    "teen": "í˜„ëŒ€ì ì´ê³  ìƒë™ê° ìˆëŠ” í‘œí˜„. ì²­ì†Œë…„ ì–¸ì–´ ë°˜ì˜.",
    "adult": "ì›ë¬¸ì˜ ë‰˜ì•™ìŠ¤ë¥¼ ì •í™•íˆ ì „ë‹¬."
}

def create_audience_prompt(texts, target):
    instruction = audience_instructions.get(target, "")
    prompt = f"""ëŒ€ìƒ ë…ì: {target}. {instruction}

ëŒ€ì‚¬: {texts}
"""
    return prompt
```

### ë¬¸í™”ì  ë§¥ë½ ì²˜ë¦¬ (cultural context)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
prompt = """ì¼ë³¸ ë¬¸í™” íŠ¹ìœ ì˜ í‘œí˜„ì€ í•œêµ­ ë…ìê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­í•˜ì„¸ìš”.
ì˜ˆì‹œ: "ãŠç›†" â†’ "ëª…ì ˆ" ë˜ëŠ” "ì¶”ì„ ê°™ì€ ëª…ì ˆ"

ëŒ€ì‚¬: {texts}
"""
```

### ë²ˆì—­ ê¸¸ì´ ì˜ˆì¸¡ (length prediction)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
def estimate_max_length(balloon_area, font_size):
    chars_per_line = int(balloon_area.width / (font_size * 0.6))
    max_lines = int(balloon_area.height / (font_size * 1.2))
    return chars_per_line * max_lines

def create_length_prompt(text, max_length):
    prompt = f"""ë²ˆì—­ ê²°ê³¼ëŠ” ê³µë°± í¬í•¨ {max_length}ì ì´ë‚´ë¡œ ì œí•œí•˜ì„¸ìš”.

ì›ë¬¸: {text}
ë²ˆì—­ (ìµœëŒ€ {max_length}ì):
"""
    return prompt
```

### API ë¹„ìš© ìµœì í™” (cost optimization)

**ìš°ì„ ìˆœìœ„**: âšª LOW

**êµ¬í˜„ ì½”ë“œ**:

```python
def optimize_batch_size(page_texts, max_tokens=4000):
    batches = []
    current_batch = []
    current_tokens = 0
    
    for text in page_texts:
        text_tokens = int(len(text.content) * 1.5)
        if current_tokens + text_tokens > max_tokens:
            batches.append(current_batch)
            current_batch = [text]
            current_tokens = text_tokens
        else:
            current_batch.append(text)
            current_tokens += text_tokens
    
    if current_batch:
        batches.append(current_batch)
    return batches
```

## STAGE â‘¢ â€” ë²ˆì—­ (LLM)

### ì§ì—­ vs ì˜ì—­ ê· í˜• ì‹¤íŒ¨ (literal vs free translation)

**ìš°ì„ ìˆœìœ„**: ğŸ”´ CRITICAL

**êµ¬í˜„ ì½”ë“œ**:

```python
def create_translation_style_prompt(text, text_type, genre):
    if text_type == "dialogue":
        style = "ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ì–´ì²´ë¡œ ì˜ì—­í•˜ì„¸ìš”. í•œêµ­ì¸ì´ ì‹¤ì œë¡œ ë§í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ."
    elif text_type == "narration":
        style = "ì •í™•í•˜ê³  ë¬¸í•™ì ìœ¼ë¡œ ì§ì—­í•˜ì„¸ìš”. ì›ë¬¸ì˜ ë‰˜ì•™ìŠ¤ë¥¼ ìœ ì§€."
    elif text_type == "SFX":
        style = "ê°„ê²°í•˜ê³  ë¦¬ë“¬ê° ìˆê²Œ. 2~4ìŒì ˆ ì˜ì„±ì–´/ì˜íƒœì–´ë¡œ."
    
    prompt = f"""{genre} ì¥ë¥´ ë§Œí™”ì…ë‹ˆë‹¤.
ë²ˆì—­ ìŠ¤íƒ€ì¼: {style}

ì›ë¬¸: {text}
ë²ˆì—­:"""
    return prompt
```

### ëŒ€ëª…ì‚¬ í•´ì„ ì˜¤ë¥˜ (pronoun resolution)

**ìš°ì„ ìˆœìœ„**: ğŸ”´ CRITICAL

**êµ¬í˜„ ì½”ë“œ**:

```python
def resolve_pronouns_in_translation(text, characters_in_context):
    char_info = ", ".join([f"{c.name}({c.gender})" for c in characters_in_context])
    
    prompt = f"""ë“±ì¥ ìºë¦­í„°: {char_info}

ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë²ˆì—­í•  ë•Œ, ëŒ€ëª…ì‚¬('å½¼', 'å½¼å¥³', 'ê·¸', 'ê·¸ë…€')ë¥¼ ë¬¸ë§¥ìƒ ëª…í™•í•œ ìºë¦­í„° ì´ë¦„ì´ë‚˜ 
ì ì ˆí•œ ëŒ€ëª…ì‚¬ë¡œ í•´ì„í•˜ì„¸ìš”.

ì›ë¬¸: {text}
ë²ˆì—­:"""
    return prompt
```

### ì¡´ëŒ“ë§/ë°˜ë§ ë¶ˆì¼ì¹˜ (honorific level mismatch)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
def apply_honorific_level(speaker, listener, relationship):
    if relationship in ["ìƒì‚¬-ë¶€í•˜", "ì„ ë°°-í›„ë°°", "ì„ ìƒ-í•™ìƒ"]:
        honorific = "ì¡´ëŒ“ë§ ì‚¬ìš© (ã€œìš”/ìŠµë‹ˆë‹¤)"
    elif relationship in ["ì¹œêµ¬", "ë™ë£Œ"]:
        honorific = "ë°˜ë§ ì‚¬ìš© (ã€œì•¼/ì–´)"
    elif speaker.age < listener.age:
        honorific = "ì¡´ëŒ“ë§ (ë‚˜ì´ ì°¨ì´ ê³ ë ¤)"
    else:
        honorific = "ì ì ˆíˆ íŒë‹¨"
    
    prompt = f"""í™”ì: {speaker.name}, ì²­ì: {listener.name}
ê´€ê³„: {relationship}
ë²ˆì—­ ì‹œ {honorific}

ì›ë¬¸: {text}"""
    return prompt
```

### ë‰˜ì•™ìŠ¤ ì†ì‹¤ (nuance loss)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
prompt = """ë²ˆì—­ ì‹œ ë‹¤ìŒ ë‰˜ì•™ìŠ¤ë¥¼ ë°˜ë“œì‹œ ìœ ì§€í•˜ì„¸ìš”:
- ì¶”ì¸¡/ë¶ˆí™•ì‹¤: ã€œã ã‚ã†, ã€œã‹ã‚‚ã—ã‚Œãªã„ â†’ '~ì¸ ê²ƒ ê°™ë‹¤', '~ì¼ì§€ë„'
- í™•ì‹ /ë‹¨ì •: ã€œã , ã€œã«é•ã„ãªã„ â†’ '~ì´ë‹¤', '~ì„ì— í‹€ë¦¼ì—†ë‹¤'
- ì˜ë¬´/ê¶Œìœ : ã€œã¹ã, ã€œãŸã»ã†ãŒã„ã„ â†’ '~í•´ì•¼ í•œë‹¤', '~í•˜ëŠ” ê²Œ ì¢‹ë‹¤'

ì›ë¬¸: {text}
ë²ˆì—­ (ë‰˜ì•™ìŠ¤ ìœ ì§€):"""
```

### SFX ë²ˆì—­ í’ˆì§ˆ (SFX translation quality)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
prompt = """íš¨ê³¼ìŒ(SFX) ë²ˆì—­ ê·œì¹™:
1. ê°„ê²°í•˜ê²Œ (2~4ìŒì ˆ)
2. ë¦¬ë“¬ê° ìœ ì§€ (ë°˜ë³µ êµ¬ì¡°)
3. ì„¤ëª… ì¶”ê°€ ê¸ˆì§€
4. ì˜ˆì‹œ: ãƒ‰ã‚­ãƒ‰ã‚­ â†’ ë‘ê·¼ë‘ê·¼, ã‚´ã‚´ã‚´ â†’ ìš°ìš°ì›…

ì›ë¬¸ SFX: {sfx}
ë²ˆì—­:"""
```

### API í˜¸ì¶œ ë¹„ìš© í­ì¦ (API cost explosion)

**ìš°ì„ ìˆœìœ„**: ğŸ”´ CRITICAL

**êµ¬í˜„ ì½”ë“œ**:

```python
# ì´ë¯¸ GAP-Bì—ì„œ êµ¬í˜„ë¨
# í˜ì´ì§€ ë‹¨ìœ„ ë°°ì¹˜ ë²ˆì—­ìœ¼ë¡œ API í˜¸ì¶œ ìµœì†Œí™”
```

### ì‘ë‹µ ì‹œê°„ ì§€ì—° (response latency)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
def optimize_prompt_length(context, max_tokens=4000):
    # í† í° ìˆ˜ ì¶”ì •
    estimated_tokens = len(context) * 1.5
    
    if estimated_tokens > max_tokens:
        # context ì¶•ì•½
        # 1. ì´ì „ í˜ì´ì§€ context: ë§ˆì§€ë§‰ 3ê°œë§Œ
        # 2. ìºë¦­í„° ì •ë³´: ì´ë¦„ê³¼ ì„±ë³„ë§Œ
        # 3. ìš©ì–´ì§‘: ìì£¼ ë‚˜ì˜¤ëŠ” ê²ƒë§Œ
        context = reduce_context(context, max_tokens)
    
    return context
```

### Rate limit ì´ˆê³¼ (rate limit exceeded)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
import time

def call_api_with_retry(prompt, max_retries=5):
    for attempt in range(max_retries):
        try:
            response = llm_api.complete(prompt)
            return response
        except RateLimitError as e:
            if attempt == max_retries - 1:
                raise
            wait_time = 2 ** attempt  # exponential backoff: 1, 2, 4, 8, 16ì´ˆ
            print(f"Rate limit hit. Waiting {wait_time}s...")
            time.sleep(wait_time)
```

### LLM ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜ (response format error)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
def parse_translation_response(response):
    # Markdown ë˜í•‘ ì œê±°
    text = response.strip()
    if text.startswith('\`\`\`json'):
        text = text[7:]  # \`\`\`json ì œê±°
    if text.endswith('\`\`\`'):
        text = text[:-3]
    
    try:
        result = json.loads(text)
        return result
    except json.JSONDecodeError:
        # ì¬ì‹œë„ ìš”ì²­
        return retry_with_format_instruction(response)
```

### ë²ˆì—­ ëˆ„ë½ (missing translations)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
def validate_translation_completeness(input_texts, translations):
    if len(input_texts) != len(translations):
        missing_indices = []
        for i, text in enumerate(input_texts):
            if i >= len(translations) or translations[i] is None:
                missing_indices.append(i)
        
        # ëˆ„ë½ëœ ê²ƒë§Œ ì¬ë²ˆì—­
        missing_texts = [input_texts[i] for i in missing_indices]
        retry_translations = llm_api.translate(missing_texts)
        
        # ë³‘í•©
        for i, idx in enumerate(missing_indices):
            translations.insert(idx, retry_translations[i])
    
    return translations
```

### Hallucination (í™˜ê°)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
prompt = """**ì¤‘ìš”**: ì›ë¬¸ì— ìˆëŠ” ë‚´ìš©ë§Œ ë²ˆì—­í•˜ì„¸ìš”.
- ì¶”ê°€ ì„¤ëª… ê¸ˆì§€
- ì¶”ì¸¡ ê¸ˆì§€
- ì›ë¬¸ì— ì—†ëŠ” ë‹¨ì–´ ì¶”ê°€ ê¸ˆì§€

ì›ë¬¸: {text}
ë²ˆì—­ (ì›ë¬¸ ì¶©ì‹¤):"""
```

### ì‘ë‹µ ë¶ˆì•ˆì •ì„± (response instability)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
response = llm_api.complete(
    prompt=translation_prompt,
    temperature=0.3,  # ë‚®ì€ temperatureë¡œ ì¼ê´€ì„± í™•ë³´
    seed=42  # ì¬í˜„ ê°€ëŠ¥ì„± (OpenAI ì§€ì›)
)
```

### ì†ŒìŠ¤ ì–¸ì–´ ìë™ ê°ì§€ ì‹¤íŒ¨ (language detection failure)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
prompt = """ë‹¤ìŒì€ **ì¼ë³¸ì–´** í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. **í•œêµ­ì–´**ë¡œ ë²ˆì—­í•˜ì„¸ìš”.

ì¼ë³¸ì–´ ì›ë¬¸: {japanese_text}
í•œêµ­ì–´ ë²ˆì—­:"""
```

### í•œì ì½ê¸° ë¶ˆì¼ì¹˜ (kanji reading inconsistency)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
# í•œì ì½ê¸° ìš©ì–´ì§‘
kanji_readings = {
    "ç”°ä¸­ç”Ÿ": "ë‹¤ë‚˜ì¹´ ë‚˜ë§ˆ",  # ì´ë¦„
    "ç”Ÿæ´»": "ì„¸ì´ì¹´ì¸ ",  # ë‹¨ì–´
}

def apply_kanji_reading_context(text):
    for kanji, reading in kanji_readings.items():
        if kanji in text:
            # ìš©ì–´ì§‘ì˜ ì½ê¸°ë¡œ ëŒ€ì²´
            pass  # ë²ˆì—­ ì‹œ ì°¸ì¡°
    return text
```

### ë²ˆì—­ ë¶ˆê°€ ì–¸ì–´ ì²˜ë¦¬ (untranslatable language)

**ìš°ì„ ìˆœìœ„**: âšª LOW

**êµ¬í˜„ ì½”ë“œ**:

```python
def handle_untranslatable(text, language_type):
    if language_type in ["ê³ ëŒ€ ì¼ë³¸ì–´", "ë°©ì–¸", "ì°½ì‘ ì–¸ì–´"]:
        return {
            "translation": text,  # ì›ë¬¸ ê·¸ëŒ€ë¡œ
            "note": f"({language_type} - ë²ˆì—­ ë¶ˆê°€)",
            "status": "untranslatable"
        }
    return standard_translate(text)
```

## GAP-C â€” ë²ˆì—­ ë§¤í•‘

### ë°°ì¹˜ ë²ˆì—­ ê²°ê³¼ ë§¤í•‘ ì‹¤íŒ¨ (batch translation mapping)

**ìš°ì„ ìˆœìœ„**: ğŸ”´ CRITICAL

**êµ¬í˜„ ì½”ë“œ**:

```python
def map_translations_to_texts(page_texts, translation_response):
    """ë°°ì¹˜ ë²ˆì—­ ê²°ê³¼ë¥¼ ì›ë³¸ í…ìŠ¤íŠ¸ì— ë§¤í•‘"""
    translations = parse_translation_response(translation_response)
    
    # ID ê¸°ë°˜ ë§¤í•‘
    mapping = {}
    for item in translations:
        text_id = item["id"]
        translation = item["translation"]
        mapping[text_id] = translation
    
    # ì›ë³¸ í…ìŠ¤íŠ¸ì— ë²ˆì—­ í• ë‹¹
    for text in page_texts:
        if text.id in mapping:
            text.translation = mapping[text.id]
            text.translation_meta = {"status": "success"}
        else:
            text.translation = None
            text.translation_meta = {"status": "missing", "needs_retry": True}
    
    return page_texts
```

### í…ìŠ¤íŠ¸ ID ë¶ˆì¼ì¹˜ (text ID mismatch)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
def validate_translation_ids(input_texts, translations):
    """ë²ˆì—­ ID ê²€ì¦"""
    input_ids = set([t.id for t in input_texts])
    translation_ids = set([t["id"] for t in translations])
    
    # ëˆ„ë½ëœ ID
    missing = input_ids - translation_ids
    if missing:
        warn(f"Missing translations for IDs: {missing}")
        # ëˆ„ë½ëœ ê²ƒë§Œ ì¬ë²ˆì—­
        missing_texts = [t for t in input_texts if t.id in missing]
        retry_translations = translate_batch(missing_texts)
        translations.extend(retry_translations)
    
    # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ID
    extra = translation_ids - input_ids
    if extra:
        warn(f"Unexpected translation IDs: {extra}")
        translations = [t for t in translations if t["id"] not in extra]
    
    return translations
```

### ìˆœì„œ ë³€ê²½ ê°ì§€ ì‹¤íŒ¨ (order change detection)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
def verify_translation_order(original_texts, translations):
    """ë²ˆì—­ ìˆœì„œ ê²€ì¦"""
    for i, (orig, trans) in enumerate(zip(original_texts, translations)):
        # LLMì—ê²Œ ì›ë¬¸ ì¼ë¶€(ì²˜ìŒ 20ì)ë¥¼ ì‘ë‹µì— í¬í•¨í•˜ë„ë¡ ìš”ì²­
        original_snippet = orig.content[:20]
        if trans.get("original_snippet") != original_snippet:
            warn(f"Translation order mismatch at index {i}")
            # ID ê¸°ë°˜ ì¬ì •ë ¬ ì‹œë„
            translations = sort_by_id(translations, original_texts)
            break
    
    return translations
```

### ì¤‘ë³µ ë§¤í•‘ (duplicate mapping)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
def detect_duplicate_translations(translations):
    """ì¤‘ë³µ ë²ˆì—­ ê°ì§€"""
    translation_texts = [t["translation"] for t in translations]
    unique_count = len(set(translation_texts))
    total_count = len(translation_texts)
    
    duplicate_ratio = 1 - (unique_count / total_count)
    
    if duplicate_ratio > 0.3:  # 30% ì´ìƒ ì¤‘ë³µ
        warn(f"High duplicate ratio: {duplicate_ratio:.1%}")
        return {"status": "suspicious", "ratio": duplicate_ratio}
    
    return {"status": "ok", "ratio": duplicate_ratio}
```

### í…ìŠ¤íŠ¸ íƒ€ì… ì†ì‹¤ (text type loss)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
class TranslatedText:
    def __init__(self, original_text):
        # ì›ë³¸ ì •ë³´
        self.id = original_text.id
        self.type = original_text.type  # dialogue, narration, SFX
        self.original = original_text.content
        self.bbox = original_text.bbox
        self.reading_order = original_text.reading_order
        self.balloon = original_text.balloon
        
        # ë²ˆì—­ ì •ë³´
        self.translation = None
        
        # ë©”íƒ€ë°ì´í„°
        self.meta = {
            "quality_score": None,
            "model_used": None,
            "retry_count": 0,
            "timestamp": None
        }
```

### ìœ„ì¹˜ ì •ë³´ ì†ì‹¤ (position loss)

**ìš°ì„ ìˆœìœ„**: ğŸ”´ CRITICAL

**êµ¬í˜„ ì½”ë“œ**:

```python
def preserve_position_info(original_text, translation):
    """ìœ„ì¹˜ ì •ë³´ ë³´ì¡´"""
    return {
        "id": original_text.id,
        "translation": translation,
        "position": {
            "bbox": original_text.bbox,  # {x, y, width, height}
            "rotation": original_text.rotation,
            "panel_id": original_text.panel_id
        }
    }
```

### ì½ê¸° ìˆœì„œ ì†ì‹¤ (reading order loss)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
def preserve_reading_order(page_texts):
    """ì½ê¸° ìˆœì„œ ìœ ì§€"""
    for i, text in enumerate(sorted(page_texts, key=lambda t: (t.y, -t.x))):
        text.reading_order = i + 1
    
    # ë²ˆì—­ í›„ì—ë„ reading_order ìœ ì§€
    return page_texts
```

### ë‹¤ì¤‘ ë§í’ì„  ë§¤í•‘ (multi-balloon mapping)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
def split_multi_sentence_translation(original, translation):
    """ë‹¤ì¤‘ ë¬¸ì¥ ë²ˆì—­ ë¶„í• """
    # ì›ë¬¸ ë¬¸ì¥ ìˆ˜
    original_sentences = original.split('ã€‚')
    original_count = len([s for s in original_sentences if s.strip()])
    
    # ë²ˆì—­ ë¬¸ì¥ ìˆ˜
    translation_sentences = translation.split('.')
    translation_count = len([s for s in translation_sentences if s.strip()])
    
    if original_count != translation_count:
        warn(f"Sentence count mismatch: {original_count} vs {translation_count}")
    
    # ê° ë¬¸ì¥ì„ ë³„ë„ ê°ì²´ë¡œ
    return [{"sentence": s.strip(), "index": i} for i, s in enumerate(translation_sentences) if s.strip()]
```

### ë¹ˆ ë²ˆì—­ ì²˜ë¦¬ (empty translation)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
def handle_empty_translation(original, translation):
    """ë¹ˆ ë²ˆì—­ ì²˜ë¦¬"""
    if not translation or translation.strip() == "":
        # fallback: ì›ë¬¸ ìœ ì§€
        return {
            "translation": original,
            "status": "fallback",
            "reason": "Empty translation - using original"
        }
    return {"translation": translation, "status": "success"}
```

### ë²ˆì—­ í›„ ë©”íƒ€ë°ì´í„° (post-translation metadata)

**ìš°ì„ ìˆœìœ„**: âšª LOW

**êµ¬í˜„ ì½”ë“œ**:

```python
def add_translation_metadata(translation, quality_score, model_name):
    """ë²ˆì—­ í›„ ë©”íƒ€ë°ì´í„° ì¶”ê°€"""
    translation.meta = {
        "quality_score": quality_score,  # 1~5
        "model_used": model_name,  # "gpt-4o", "gemini-flash"
        "retry_count": translation.get("retry_count", 0),
        "timestamp": datetime.now().isoformat(),
        "confidence": translation.get("confidence", None)
    }
    return translation
```

## STAGE â‘£ â€” í…ìŠ¤íŠ¸ ì œê±° & ì‚½ì…

### ìŠ¤í¬ë¦°í†¤ íŒ¨í„´ íŒŒê´´ (CRITICAL)

**ìš°ì„ ìˆœìœ„**: ğŸ”´ CRITICAL

**êµ¬í˜„ ì½”ë“œ**:

```python
import cv2
import numpy as np
from numpy.fft import fft2, fftshift

# 1. ì£¼ë³€ ì˜ì—­ì—ì„œ íŒ¨í„´ ê°ì§€
surrounding = get_surrounding_region(inpaint_mask, padding=50)
f_transform = fft2(surrounding)
f_shift = fftshift(f_transform)
magnitude = np.abs(f_shift)

# 2. ì£¼íŒŒìˆ˜ ë„ë©”ì¸ì—ì„œ í”¼í¬ ì°¾ê¸° (íŒ¨í„´ ì£¼ê¸°)
peaks = find_frequency_peaks(magnitude)
pattern_tile = reconstruct_pattern_tile(peaks)

# 3. íŒ¨í„´ íƒ€ì¼ì„ inpaint ì˜ì—­ì— ë°°ì¹˜
inpaint_region = tile_pattern(pattern_tile, inpaint_mask.shape)

# 4. LaMa inpainting ì ìš© í›„ alpha blend
lama_result = lama.inpaint(image, inpaint_mask)
final = cv2.addWeighted(inpaint_region, 0.3, lama_result, 0.7, 0)
```

### ë³µì¡í•œ ë°°ê²½ ë³µì› ì‹¤íŒ¨ (ì¸ë¬¼ ë’¤, ê±´ë¬¼)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
# ë°°ê²½ ë³µì¡ë„ ì¸¡ì •
edges = cv2.Canny(surrounding_region, 50, 150)
edge_density = np.sum(edges > 0) / edges.size

# ì„ê³„ê°’ ì´ìƒì´ë©´ SD inpainting ì‚¬ìš©
if edge_density > 0.3:
    from diffusers import StableDiffusionInpaintPipeline
    pipe = StableDiffusionInpaintPipeline.from_pretrained(
        "stabilityai/stable-diffusion-2-inpainting"
    )
    result = pipe(
        image=image,
        mask_image=mask,
        prompt="fill the area naturally with similar background",
        strength=0.8
    ).images[0]
else:
    result = lama.inpaint(image, mask)
```

### í…ìŠ¤íŠ¸ ì˜ì—­ ê²½ê³„ì˜ halo effect

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**ë¬¸ì œì **: inpaintëœ ì˜ì—­ê³¼ ì›ë³¸ ì´ë¯¸ì§€ì˜ ê²½ê³„ì—ì„œ ìƒ‰ìƒ/ë°ê¸°ê°€ ë¯¸ë¬˜í•˜ê²Œ ë‹¬ë¼ 'í›„ê´‘ íš¨ê³¼' ìƒê¹€.

**í•´ê²°ì±…**: inpaint í›„ Poisson blending (cv2.seamlessClone) ì ìš©í•´ ê²½ê³„ ìì—°ìŠ¤ëŸ½ê²Œ

**êµ¬í˜„ ì½”ë“œ**:

```python
# Poisson blendingìœ¼ë¡œ ê²½ê³„ ë¶€ë“œëŸ½ê²Œ
center = (inpaint_region.x + inpaint_region.width // 2,
          inpaint_region.y + inpaint_region.height // 2)
result = cv2.seamlessClone(
    inpainted_region,
    original_image,
    mask,
    center,
    cv2.NORMAL_CLONE
)
```

### í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€ ì˜¤ë¥˜ë¡œ ì¼ë¶€ë§Œ ì œê±°

**ìš°ì„ ìˆœìœ„**: ğŸ”´ CRITICAL

**í•´ê²°ì±…**: í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€ ì‹œ bounding boxë¥¼ ì˜ë„ì ìœ¼ë¡œ í™•ì¥ (padding +5~10px)

**êµ¬í˜„ ì½”ë“œ**:

```python
# bounding box í™•ì¥
padding = 10
expanded_bbox = {
    "x": bbox.x - padding,
    "y": bbox.y - padding,
    "width": bbox.width + 2 * padding,
    "height": bbox.height + 2 * padding
}

# morphological dilationìœ¼ë¡œ mask íŒ½ì°½
kernel = np.ones((5, 5), np.uint8)
dilated_mask = cv2.dilate(text_mask, kernel, iterations=2)
```

### ë°˜íˆ¬ëª… í…ìŠ¤íŠ¸ ì”ì—¬ (ì•¤í‹°ì•¨ë¦¬ì–´ì‹±)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**í•´ê²°ì±…**: inpaint maskë¥¼ ìƒì„±í•  ë•Œ alpha mask ì‚¬ìš©. ë°˜íˆ¬ëª… ì˜ì—­ë„ í¬í•¨í•˜ë„ë¡ ì„ê³„ê°’ ë‚®ì¶¤

**êµ¬í˜„ ì½”ë“œ**:

```python
# í…ìŠ¤íŠ¸ ì˜ì—­ì„ Gaussian blurí•œ í›„ ì„ê³„ê°’ ë‚®ì¶¤
blurred = cv2.GaussianBlur(text_region, (5, 5), 0)
_, alpha_mask = cv2.threshold(blurred, 0.3 * 255, 255, cv2.THRESH_BINARY)
```

### ë§í’ì„  ê¼¬ë¦¬ ì†ìƒ

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**í•´ê²°ì±…**: ë§í’ì„  ê²½ê³„ ê°ì§€ í›„ ê¼¬ë¦¬ëŠ” convex hull ë°”ê¹¥ ë¶€ë¶„ìœ¼ë¡œ íŒë‹¨, inpaint maskì—ì„œ ì œì™¸

**êµ¬í˜„ ì½”ë“œ**:

```python
# GAP-Aì—ì„œ ì´ë¯¸ ì–¸ê¸‰í•œ ì½”ë“œì™€ ë™ì¼
hull = cv2.convexHull(contour)
tail_mask = cv2.subtract(contour_mask, hull_mask)
final_mask = cv2.bitwise_and(text_mask, cv2.bitwise_not(tail_mask))
```

### í…ìŠ¤íŠ¸ê°€ ë§í’ì„  ê²½ê³„ë¥¼ ë²—ì–´ë‚¨ (CRITICAL)

**ìš°ì„ ìˆœìœ„**: ğŸ”´ CRITICAL

**êµ¬í˜„ ì½”ë“œ**:

```python
from PIL import ImageDraw, ImageFont
import textwrap

balloon_width, balloon_height = calculate_balloon_size(contour)
font_size = 16
min_font_size = 10

while True:
    font = ImageFont.truetype("NotoSansKR.ttf", font_size)
    bbox = draw.textbbox((0, 0), translated_text, font=font)
    text_width = bbox[2] - bbox[0]
    text_height = bbox[3] - bbox[1]
    
    if text_width <= balloon_width and text_height <= balloon_height:
        break  # ë“¤ì–´ê°
    
    if font_size > min_font_size:
        font_size -= 1  # í°íŠ¸ ì¶•ì†Œ
    else:
        # ìµœì†Œ í¬ê¸°ì— ë„ë‹¬ â†’ ì¤„ë°”ê¿ˆ ì‹œë„
        wrapped = textwrap.fill(translated_text, width=balloon_width // (font_size * 0.6))
        if calculate_height(wrapped) <= balloon_height:
            translated_text = wrapped
            break
        else:
            # ì¤„ë°”ê¿ˆë„ ì•ˆ ë¨ â†’ ìˆ˜ë™ ê²€ì¦ í
            manual_review_queue.append({"reason": "text overflow", "text": translated_text})
            break
```

### í…ìŠ¤íŠ¸ ì¤‘ì‹¬ì´ ë§í’ì„  ì¤‘ì‹¬ê³¼ ì•ˆ ë§ìŒ (off-center)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**í•´ê²°ì±…**: ë§í’ì„ ì˜ ë¬´ê²Œì¤‘ì‹¬(centroid) ê³„ì‚° â†’ í…ìŠ¤íŠ¸ì˜ ì¤‘ì‹¬ì„ ë§í’ì„  ì¤‘ì‹¬ì— ë§ì¶¤

**êµ¬í˜„ ì½”ë“œ**:

```python
# ë§í’ì„  ë¬´ê²Œì¤‘ì‹¬ ê³„ì‚°
M = cv2.moments(contour)
cx = int(M['m10'] / M['m00'])
cy = int(M['m01'] / M['m00'])

# í…ìŠ¤íŠ¸ ë Œë”ë§ ì‹œ ì¤‘ì‹¬ ì •ë ¬ (Pillow anchor='mm')
draw.text((cx, cy), translated_text, font=font, fill="black", anchor="mm")
```

### ì„¸ë¡œ í…ìŠ¤íŠ¸ ë°°ì¹˜ ì˜¤ë¥˜

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
if text_direction == "vertical":
    # ê¸€ìë¥¼ í•œ ê¸€ìì”© ìˆ˜ì§ìœ¼ë¡œ ë°°ì¹˜
    y_offset = 0
    for char in translated_text:
        draw.text((cx, cy + y_offset), char, font=font, fill="black", anchor="mm")
        y_offset += font.getbbox(char)[3] + 5  # ê¸€ì ë†’ì´ + ê°„ê²©
else:
    # ê°€ë¡œì“°ê¸°
    draw.text((cx, cy), translated_text, font=font, fill="black", anchor="mm")
```

### í°íŠ¸ ì¢…ë¥˜ê°€ ì›ë³¸ê³¼ ì™„ì „íˆ ë‹¤ë¦„

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**í•´ê²°ì±…**: í…ìŠ¤íŠ¸ ì¢…ë¥˜ì— ë”°ë¼ í°íŠ¸ ë§¤í•‘: ëŒ€í™” â†’ ë‘¥ê·¼ ê³ ë”•, SFX â†’ Impact, ë‚˜ë ˆì´ì…˜ â†’ ì„¸ë¦¬í”„

**êµ¬í˜„ ì½”ë“œ**:

```python
FONT_MAPPING = {
    "dialogue": "NotoSansKR-Regular.ttf",
    "SFX": "Impact.ttf",
    "narration": "NotoSerifKR.ttf",
    "small_text": "NotoSansKR-Light.ttf"
}

font_path = FONT_MAPPING.get(text_type, "NotoSansKR-Regular.ttf")
font = ImageFont.truetype(font_path, font_size)
```

### í°íŠ¸ í¬ê¸° ìë™ ì¶•ì†Œì˜ í•œê³„ (ìµœì†Œ í¬ê¸°)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**êµ¬í˜„ ì½”ë“œ**:

```python
MIN_FONT_SIZE = 10

if font_size <= MIN_FONT_SIZE and text_still_overflows:
    # í…ìŠ¤íŠ¸ë¥¼ LLMì—ê²Œ ìš”ì•½ ìš”ì²­
    summarized = llm.summarize(translated_text, max_chars=balloon_width // MIN_FONT_SIZE)
    translated_text = summarized
```

### í•œê¸€ í°íŠ¸ì˜ ìê°„Â·í–‰ê°„ ë¬¸ì œ

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
# PillowëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ìê°„ ì¡°ì • ë¯¸ì§€ì› â†’ ìˆ˜ë™ìœ¼ë¡œ ê¸€ìë³„ x ì¢Œí‘œ ì¡°ì •
def draw_text_with_spacing(draw, text, position, font, spacing=0):
    x, y = position
    for char in text:
        draw.text((x, y), char, font=font, fill="black")
        bbox = font.getbbox(char)
        x += (bbox[2] - bbox[0]) + spacing  # ê¸€ì ë„ˆë¹„ + ìê°„
```

### í…ìŠ¤íŠ¸ê°€ ë§í’ì„  í…Œë‘ë¦¬ì™€ ê²¹ì¹¨

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**ë¬¸ì œì **: ë§í’ì„  ë‚´ë¶€ ì˜ì—­ì„ ê³„ì‚°í•  ë•Œ í…Œë‘ë¦¬ ë‘ê»˜ë¥¼ ê³ ë ¤í•˜ì§€ ì•Šì•„, í…ìŠ¤íŠ¸ê°€ í…Œë‘ë¦¬ ì„ ê³¼ ê²¹ì³ ì½ê¸° ì–´ë ¤ì›€.

**í•´ê²°ì±…**: ë§í’ì„  ê²½ê³„ ê°ì§€ í›„ ë‚´ë¶€ ì˜ì—­ì—ì„œ ë§ˆì§„ ì ìš© (erode)

**êµ¬í˜„ ì½”ë“œ**:

```python
# ì´ë¯¸ GAP-Aì—ì„œ ë‹¤ë¤˜ìŒ
kernel = np.ones((5, 5), np.uint8)
inner_balloon = cv2.erode(balloon_mask, kernel, iterations=1)
```

### ë¶ˆê·œì¹™í•œ ë§í’ì„ (êµ¬ë¦„í˜•Â·í­ë°œí˜•) ì²˜ë¦¬ ì‹¤íŒ¨

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**í•´ê²°ì±…**: ë¶ˆê·œì¹™í•œ ë§í’ì„ ì€ convex hullë¡œ ê·¼ì‚¬. ë˜ëŠ” ìµœëŒ€ ë‚´ì ‘ ì› ê³„ì‚°í•´ ê·¸ ì•ˆì—ë§Œ í…ìŠ¤íŠ¸ ë°°ì¹˜

**êµ¬í˜„ ì½”ë“œ**:

```python
# convex hullë¡œ ë‹¨ìˆœí™”
hull = cv2.convexHull(irregular_contour)

# ë˜ëŠ” distance transformìœ¼ë¡œ ìµœëŒ€ ë‚´ì ‘ ì› ì°¾ê¸°
dist_transform = cv2.distanceTransform(balloon_mask, cv2.DIST_L2, 5)
_, radius, _, center = cv2.minMaxLoc(dist_transform)
# center ì•ˆì—ë§Œ í…ìŠ¤íŠ¸ ë°°ì¹˜
```

### ê²¹ì¹˜ëŠ” ë§í’ì„  ì²˜ë¦¬ (ì—°ì† ëŒ€í™”)

**ìš°ì„ ìˆœìœ„**: âšª LOW

**í•´ê²°ì±…**: ë§í’ì„  ê°„ ì¶©ëŒ ê°ì§€ â†’ ê²¹ì¹˜ëŠ” ì˜ì—­ì´ ìˆìœ¼ë©´ ê° ë§í’ì„ ì˜ 'ë°°íƒ€ì  ì˜ì—­'ë§Œ í…ìŠ¤íŠ¸ ë°°ì¹˜ ê°€ëŠ¥ ì˜ì—­ìœ¼ë¡œ

**êµ¬í˜„ ì½”ë“œ**:

```python
# ë§í’ì„  contourë¼ë¦¬ AND ì—°ì‚°ìœ¼ë¡œ ê²¹ì¹˜ëŠ” ì˜ì—­ ê³„ì‚°
overlap = cv2.bitwise_and(balloon1_mask, balloon2_mask)
if np.sum(overlap) > 0:
    # ê²¹ì¹˜ëŠ” ì˜ì—­ì€ 'ë¨¼ì € ì˜¤ëŠ”' ë§í’ì„ ì— í• ë‹¹
    balloon1_exclusive = cv2.bitwise_and(balloon1_mask, cv2.bitwise_not(overlap))
```

### í…ìŠ¤íŠ¸ ë Œë”ë§ ì‹œ ì•¤í‹°ì•¨ë¦¬ì–´ì‹± ë¶ˆì¼ì¹˜

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**êµ¬í˜„ ì½”ë“œ**:

```python
# ì›ë³¸ í…ìŠ¤íŠ¸ê°€ í”½ì…€ì•„íŠ¸ ëŠë‚Œì´ë©´ nearest-neighbor scalingìœ¼ë¡œ í”½ì…€í™”
if original_style == "pixel_art":
    text_layer = cv2.resize(text_layer, text_layer.shape[:2][::-1], 
                            interpolation=cv2.INTER_NEAREST)
```

### í…ìŠ¤íŠ¸ ê·¸ë¦¼ìÂ·ì™¸ê³½ì„  ë¶€ì¬

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**í•´ê²°ì±…**: ì›ë³¸ í…ìŠ¤íŠ¸ì— ì™¸ê³½ì„ ì´ ìˆìœ¼ë©´, ìƒˆ í…ìŠ¤íŠ¸ì—ë„ ë™ì¼í•œ ì™¸ê³½ì„  ì¶”ê°€ (PIL stroke_width)

**êµ¬í˜„ ì½”ë“œ**:

```python
# ì™¸ê³½ì„ 
draw.text((x, y), text, font=font, fill="white", 
          stroke_width=2, stroke_fill="black")

# ê·¸ë¦¼ì (í…ìŠ¤íŠ¸ë¥¼ ë‘ ë²ˆ ë Œë”ë§)
draw.text((x+2, y+2), text, font=font, fill="black")  # ê·¸ë¦¼ì
draw.text((x, y), text, font=font, fill="white")  # ì‹¤ì œ í…ìŠ¤íŠ¸
```

### ìµœì¢… ì´ë¯¸ì§€ ì••ì¶• ì‹œ í’ˆì§ˆ ì €í•˜

**ìš°ì„ ìˆœìœ„**: âšª LOW

**í•´ê²°ì±…**: í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ì˜ì—­ì€ ê³ í’ˆì§ˆë¡œ ì••ì¶• (JPEG quality 95+) ë˜ëŠ” PNGë¡œ ì €ì¥

**êµ¬í˜„ ì½”ë“œ**:

```python
from PIL import Image
image.save("output.jpg", format="JPEG", quality=95)
# ë˜ëŠ”
image.save("output.webp", format="WEBP", quality=90)  # WebPëŠ” ì†ì‹¤ ì••ì¶•ì´ì§€ë§Œ í’ˆì§ˆ ì¢‹ìŒ
```

## POST-PROCESSING

### ë²ˆì—­ ëˆ„ë½ ê²€ì¦ (translation completeness)

**ìš°ì„ ìˆœìœ„**: ğŸ”´ CRITICAL

**ID**: `post-1`

**ë¬¸ì œì **:
ì¼ë¶€ í…ìŠ¤íŠ¸ê°€ ë²ˆì—­ ì•ˆ ë¨. Stageâ‘¡ì—ì„œ 100ê°œ ê°ì§€ â†’ Stageâ‘¢ì—ì„œ 95ê°œë§Œ ë²ˆì—­ â†’ 5ê°œ ëˆ„ë½. ìµœì¢… ì¶œë ¥ì—ì„œ ì›ë³¸ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ë‚¨ìŒ.

**í•´ê²°ì±…**:
ì…ë ¥ í…ìŠ¤íŠ¸ ê°œìˆ˜ == ì¶œë ¥ ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ê°œìˆ˜ ê²€ì¦. ëˆ„ë½ ë¦¬ìŠ¤íŠ¸ ìë™ ìƒì„± + ê²½ê³ 

**êµ¬í˜„ ì½”ë“œ**:

```python
def validate_translation_completeness(ocr_results, rendered_page):
    """ë²ˆì—­ ëˆ„ë½ ê²€ì¦"""
    original_count = len(ocr_results)
    
    # ë Œë”ë§ëœ í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€
    rendered_text_regions = detect_text_regions(rendered_page)
    rendered_count = len(rendered_text_regions)
    
    if original_count != rendered_count:
        missing_count = original_count - rendered_count
        warn(f"ë²ˆì—­ ëˆ„ë½: {missing_count}ê°œ")
        
        # ëˆ„ë½ëœ í…ìŠ¤íŠ¸ ì°¾ê¸°
        missing_texts = find_missing_texts(ocr_results, rendered_text_regions)
        
        return {
            "status": "incomplete",
            "missing_count": missing_count,
            "missing_texts": missing_texts
        }
    
    return {"status": "complete"}
```

---

### ì‹œê°ì  í’ˆì§ˆ ê²€ì¦ (visual quality check)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**ID**: `post-2`

**ë¬¸ì œì **:
í…ìŠ¤íŠ¸ê°€ ë§í’ì„  ë°–ìœ¼ë¡œ íŠ€ì–´ë‚˜ê°. í°íŠ¸ê°€ ë„ˆë¬´ ì‘ìŒ (<8pt). ì¤„ë°”ê¿ˆì´ ì´ìƒí•¨. ìë™ ê²€ì¦ ì—†ì´ ìˆ˜ë™ìœ¼ë¡œë§Œ í™•ì¸.

**í•´ê²°ì±…**:
ìë™ í’ˆì§ˆ ê²€ì‚¬ - bbox overflow ì²´í¬, í°íŠ¸ í¬ê¸° < 8pt ê²½ê³ , í…ìŠ¤íŠ¸ ë°€ë„ > 90% ê²½ê³ 

**êµ¬í˜„ ì½”ë“œ**:

```python
def validate_visual_quality(page_image, text_regions):
    """ì‹œê°ì  í’ˆì§ˆ ìë™ ê²€ì¦"""
    issues = []
    
    for region in text_regions:
        # 1. Bbox overflow
        if region.bbox.x < 0 or region.bbox.y < 0:
            issues.append({
                "type": "bbox_overflow",
                "region": region.id,
                "severity": "high"
            })
        
        # 2. í°íŠ¸ í¬ê¸°
        if region.font_size < 8:
            issues.append({
                "type": "font_too_small",
                "region": region.id,
                "font_size": region.font_size
            })
        
        # 3. í…ìŠ¤íŠ¸ ë°€ë„
        density = calculate_text_density(region)
        if density > 0.9:
            issues.append({
                "type": "text_density_high",
                "region": region.id,
                "density": density
            })
    
    return issues
```

---

### ë²ˆì—­ ì¼ê´€ì„± ê²€ì¦ (translation consistency)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**ID**: `post-3`

**ë¬¸ì œì **:
ê°™ì€ í˜ì´ì§€ì—ì„œ ìºë¦­í„° ì´ë¦„ ë¶ˆì¼ì¹˜. 1í˜ì´ì§€: 'ë‹¤ë‚˜ì¹´', 2í˜ì´ì§€: 'íƒ€ë‚˜ì¹´', 3í˜ì´ì§€: 'ë‹¤ë‚˜ì¹´'. ë…ì í˜¼ë€.

**í•´ê²°ì±…**:
ìºë¦­í„° ì´ë¦„ ë”•ì…”ë„ˆë¦¬ ê¸°ë°˜ ê²€ì¦. ë¶ˆì¼ì¹˜ ê°ì§€ ì‹œ ê²½ê³  + ìˆ˜ì • ì œì•ˆ

**êµ¬í˜„ ì½”ë“œ**:

```python
def validate_name_consistency(pages, character_dict):
    """ì´ë¦„ ì¼ê´€ì„± ê²€ì¦"""
    inconsistencies = []
    
    for page in pages:
        for text in page.texts:
            if text.translation:
                # ë”•ì…”ë„ˆë¦¬ì— ìˆëŠ” ì´ë¦„ ì°¾ê¸°
                for original_name, standard_name in character_dict.items():
                    if original_name in text.original:
                        # ë²ˆì—­ì— í‘œì¤€ ì´ë¦„ì´ ìˆëŠ”ì§€ í™•ì¸
                        if standard_name not in text.translation:
                            # ë‹¤ë¥¸ ë³€í˜• ì°¾ê¸°
                            found_variant = find_name_variant(text.translation, standard_name)
                            if found_variant:
                                inconsistencies.append({
                                    "page": page.number,
                                    "text_id": text.id,
                                    "expected": standard_name,
                                    "found": found_variant
                                })
    
    return inconsistencies
```

---

### í…ìŠ¤íŠ¸ ê°€ë…ì„± ê²€ì¦ (readability check)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**ID**: `post-4`

**ë¬¸ì œì **:
ë°°ê²½ê³¼ í…ìŠ¤íŠ¸ ìƒ‰ìƒ ëŒ€ë¹„ ë¶€ì¡±. í° ë°°ê²½ì— í° í…ìŠ¤íŠ¸. WCAG ê¸°ì¤€ (4.5:1) ë¯¸ë‹¬.

**í•´ê²°ì±…**:
ìƒ‰ìƒ ëŒ€ë¹„ ë¹„ìœ¨ ê³„ì‚°. ë¶€ì¡±í•˜ë©´ ì™¸ê³½ì„  ì¶”ê°€ ê¶Œì¥

**êµ¬í˜„ ì½”ë“œ**:

```python
def calculate_contrast_ratio(text_color, background_color):
    """WCAG ìƒ‰ìƒ ëŒ€ë¹„ ë¹„ìœ¨"""
    def relative_luminance(rgb):
        r, g, b = [x / 255.0 for x in rgb]
        r = r / 12.92 if r <= 0.03928 else ((r + 0.055) / 1.055) ** 2.4
        g = g / 12.92 if g <= 0.03928 else ((g + 0.055) / 1.055) ** 2.4
        b = b / 12.92 if b <= 0.03928 else ((b + 0.055) / 1.055) ** 2.4
        return 0.2126 * r + 0.7152 * g + 0.0722 * b
    
    l1 = relative_luminance(text_color)
    l2 = relative_luminance(background_color)
    
    lighter = max(l1, l2)
    darker = min(l1, l2)
    
    return (lighter + 0.05) / (darker + 0.05)

def validate_readability(text_regions):
    """ê°€ë…ì„± ê²€ì¦"""
    issues = []
    
    for region in text_regions:
        contrast = calculate_contrast_ratio(region.text_color, region.background_color)
        
        if contrast < 4.5:  # WCAG AA ê¸°ì¤€
            issues.append({
                "region": region.id,
                "contrast": contrast,
                "recommendation": "Add stroke or change color"
            })
    
    return issues
```

---

### ë‹¤ì–‘í•œ ì¶œë ¥ í˜•ì‹ ì§€ì› (multiple formats)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**ID**: `post-5`

**ë¬¸ì œì **:
ì´ë¯¸ì§€ë§Œ ì¶œë ¥. PDF/CBZ/EPUB í•„ìš”. ê° í”Œë«í¼ë§ˆë‹¤ ë‹¤ë¥¸ í˜•ì‹ ìš”êµ¬.

**í•´ê²°ì±…**:
Pillow â†’ PDF (img2pdf), CBZ (zipfile), EPUB (ebooklib) ë³€í™˜ ì§€ì›

**êµ¬í˜„ ì½”ë“œ**:

```python
def export_to_format(pages, output_format="pdf"):
    """ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥"""
    if output_format == "pdf":
        import img2pdf
        
        image_files = [page.rendered_image_path for page in pages]
        pdf_bytes = img2pdf.convert(image_files)
        
        with open("output.pdf", "wb") as f:
            f.write(pdf_bytes)
    
    elif output_format == "cbz":
        import zipfile
        
        with zipfile.ZipFile("output.cbz", 'w') as z:
            for i, page in enumerate(pages):
                z.write(page.rendered_image_path, f"page_{i+1:03d}.png")
    
    elif output_format == "epub":
        from ebooklib import epub
        
        book = epub.EpubBook()
        for i, page in enumerate(pages):
            image = epub.EpubImage()
            image.file_name = f"page_{i+1}.png"
            image.content = open(page.rendered_image_path, 'rb').read()
            book.add_item(image)
        
        epub.write_epub('output.epub', book)
```

---

### ì›ë³¸ ë©”íƒ€ë°ì´í„° ë³´ì¡´ (metadata preservation)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**ID**: `post-6`

**ë¬¸ì œì **:
EXIF ë°ì´í„°, í˜ì´ì§€ ìˆœì„œ, íŒŒì¼ëª… ì†ì‹¤. ì›ë³¸: '001_cover.jpg' â†’ ì¶œë ¥: 'page_1.png'.

**í•´ê²°ì±…**:
ì›ë³¸ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ â†’ ì¶œë ¥ íŒŒì¼ì— ì¬ì ìš©

**êµ¬í˜„ ì½”ë“œ**:

```python
from PIL import Image
from PIL.ExifTags import TAGS

def preserve_metadata(original_image, translated_image):
    """ë©”íƒ€ë°ì´í„° ë³´ì¡´"""
    # EXIF ì¶”ì¶œ
    exif = original_image.getexif()
    
    # ë²ˆì—­ëœ ì´ë¯¸ì§€ì— ì ìš©
    if exif:
        translated_image.save("output.jpg", exif=exif)
    
    return translated_image

def preserve_filenames(original_files, translated_files):
    """íŒŒì¼ëª… êµ¬ì¡° ë³´ì¡´"""
    import os
    
    for orig_path, trans_path in zip(original_files, translated_files):
        # ì›ë³¸ íŒŒì¼ëª… ì¶”ì¶œ
        orig_name = os.path.basename(orig_path)
        name_without_ext = os.path.splitext(orig_name)[0]
        
        # ë²ˆì—­ íŒŒì¼ëª…ì— ì ìš©
        new_name = f"{name_without_ext}_translated.png"
        os.rename(trans_path, new_name)
```

---

### ì••ì¶• ìµœì í™” (compression optimization)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**ID**: `post-7`

**ë¬¸ì œì **:
PNG ì¶œë ¥ ì‹œ íŒŒì¼ í¬ê¸° ê±°ëŒ€ (10MB/page). ì›¹ ë°°í¬ ì‹œ ë¡œë”© ëŠë¦¼.

**í•´ê²°ì±…**:
JPEG í’ˆì§ˆ 90% (ì‹œê°ì  ì°¨ì´ ì—†ìŒ), PNG ìµœì í™”, WebP ì˜µì…˜

**êµ¬í˜„ ì½”ë“œ**:

```python
def optimize_output(image, format="jpeg", quality=90):
    """ì¶œë ¥ ìµœì í™”"""
    if format == "jpeg":
        image.save("output.jpg", "JPEG", quality=quality, optimize=True)
    
    elif format == "png":
        # PNG ìµœì í™” (pngquant ì‚¬ìš©)
        import subprocess
        image.save("temp.png")
        subprocess.run(["pngquant", "--force", "--output", "output.png", "temp.png"])
    
    elif format == "webp":
        image.save("output.webp", "WEBP", quality=quality, method=6)
```

---

### Before/After ë¹„êµ ì´ë¯¸ì§€ (comparison)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**ID**: `post-8`

**ë¬¸ì œì **:
ë²ˆì—­ í’ˆì§ˆ í™•ì¸ ì–´ë ¤ì›€. ì›ë³¸ê³¼ ë¹„êµ ëª» í•¨. ìˆ˜ë™ìœ¼ë¡œ ì´ë¯¸ì§€ 2ê°œ ì—´ì–´ì„œ ë¹„êµ.

**í•´ê²°ì±…**:
ì¢Œìš° ë¹„êµ ì´ë¯¸ì§€ ìë™ ìƒì„±. ìŠ¬ë¼ì´ë” UIë¡œ ì „/í›„ ë¹„êµ

**êµ¬í˜„ ì½”ë“œ**:

```python
def generate_comparison_image(original, translated):
    """ì¢Œìš° ë¹„êµ ì´ë¯¸ì§€"""
    from PIL import Image, ImageDraw
    
    width = original.width + translated.width + 20
    height = max(original.height, translated.height)
    
    comparison = Image.new('RGB', (width, height), (255, 255, 255))
    
    # ì›ë³¸ ì™¼ìª½
    comparison.paste(original, (0, 0))
    
    # êµ¬ë¶„ì„ 
    draw = ImageDraw.Draw(comparison)
    draw.line([(original.width + 10, 0), 
               (original.width + 10, height)], 
              fill=(200, 200, 200), width=2)
    
    # ë²ˆì—­ ì˜¤ë¥¸ìª½
    comparison.paste(translated, (original.width + 20, 0))
    
    # ë¼ë²¨ ì¶”ê°€
    draw.text((10, 10), "Original", fill=(0, 0, 0))
    draw.text((original.width + 30, 10), "Translated", fill=(0, 0, 0))
    
    return comparison
```

---

### ë²ˆì—­ í†µê³„ ìƒì„± (translation statistics)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**ID**: `post-9`

**ë¬¸ì œì **:
ì–¼ë§ˆë‚˜ ë²ˆì—­í–ˆëŠ”ì§€ ëª¨ë¦„. ì„±ê³µë¥ , ì‹¤íŒ¨ìœ¨, í‰ê·  confidence ì•Œ ìˆ˜ ì—†ìŒ.

**í•´ê²°ì±…**:
í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ê°œìˆ˜, ë²ˆì—­ë¥ , í‰ê·  confidence, ì‹¤íŒ¨ ì¼€ì´ìŠ¤ í†µê³„ ìƒì„±

**êµ¬í˜„ ì½”ë“œ**:

```python
def generate_translation_statistics(pages):
    """ë²ˆì—­ í†µê³„"""
    stats = {
        "total_pages": len(pages),
        "total_texts": 0,
        "translated_texts": 0,
        "failed_texts": 0,
        "average_confidence": 0,
        "by_type": {
            "dialogue": {"count": 0, "success": 0},
            "narration": {"count": 0, "success": 0},
            "SFX": {"count": 0, "success": 0}
        }
    }
    
    confidences = []
    
    for page in pages:
        for text in page.texts:
            stats["total_texts"] += 1
            
            if text.translation:
                stats["translated_texts"] += 1
                stats["by_type"][text.type]["success"] += 1
                if text.translation_meta.get("confidence"):
                    confidences.append(text.translation_meta["confidence"])
            else:
                stats["failed_texts"] += 1
            
            stats["by_type"][text.type]["count"] += 1
    
    if confidences:
        stats["average_confidence"] = sum(confidences) / len(confidences)
    
    stats["translation_rate"] = stats["translated_texts"] / stats["total_texts"]
    
    return stats
```

---

### ìƒì„¸ ë¡œê·¸ íŒŒì¼ (detailed logging)

**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ MEDIUM

**ID**: `post-10`

**ë¬¸ì œì **:
ì˜¤ë¥˜ ë°œìƒ ì‹œ ë””ë²„ê¹… ì–´ë ¤ì›€. ì–´ëŠ stageì—ì„œ ì‹¤íŒ¨í–ˆëŠ”ì§€, ì–¼ë§ˆë‚˜ ê±¸ë ¸ëŠ”ì§€ ì•Œ ìˆ˜ ì—†ìŒ.

**í•´ê²°ì±…**:
JSON ë¡œê·¸ - ê° stageë³„ ì‹œê°„, ì„±ê³µ/ì‹¤íŒ¨, ì˜¤ë¥˜ ë©”ì‹œì§€, ì…ì¶œë ¥ ë°ì´í„°

**êµ¬í˜„ ì½”ë“œ**:

```python
import json
import time

class PipelineLogger:
    def __init__(self):
        self.logs = []
    
    def log_stage(self, stage_name, status, duration, details=None):
        """Stage ë¡œê·¸ ê¸°ë¡"""
        log_entry = {
            "timestamp": time.time(),
            "stage": stage_name,
            "status": status,  # "success" or "failed"
            "duration_seconds": duration,
            "details": details or {}
        }
        self.logs.append(log_entry)
    
    def save_to_file(self, filepath="pipeline_log.json"):
        """ë¡œê·¸ íŒŒì¼ ì €ì¥"""
        with open(filepath, 'w') as f:
            json.dump(self.logs, f, indent=2)

# ì‚¬ìš© ì˜ˆ
logger = PipelineLogger()

start_time = time.time()
try:
    result = run_ocr_stage(page)
    logger.log_stage("OCR", "success", time.time() - start_time, 
                      {"text_count": len(result)})
except Exception as e:
    logger.log_stage("OCR", "failed", time.time() - start_time,
                      {"error": str(e)})
```

---

### ìˆ˜ë™ ê²€ì¦ í (manual review queue)

**ìš°ì„ ìˆœìœ„**: ğŸŸ  HIGH

**ID**: `post-11`

**ë¬¸ì œì **:
ìë™ ë²ˆì—­ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ìˆ˜ë™ ì²˜ë¦¬ í•„ìš”. í•˜ì§€ë§Œ ì–´ë–¤ ê²ƒì´ ì‹¤íŒ¨í–ˆëŠ”ì§€ ì°¾ê¸° ì–´ë ¤ì›€.

**í•´ê²°ì±…**:
ì‹¤íŒ¨ ì¼€ì´ìŠ¤ë¥¼ ë³„ë„ í´ë”ì— ì €ì¥. ì›¹ UIë¡œ ìˆ˜ë™ ìˆ˜ì • í›„ ì¬ì²˜ë¦¬

**êµ¬í˜„ ì½”ë“œ**:

```python
import os
import shutil

class ManualReviewQueue:
    def __init__(self, queue_dir="./manual_review"):
        self.queue_dir = queue_dir
        os.makedirs(queue_dir, exist_ok=True)
        self.queue = []
    
    def add_to_queue(self, page_id, reason, image, metadata):
        """íì— ì¶”ê°€"""
        item = {
            "page_id": page_id,
            "reason": reason,
            "timestamp": time.time(),
            "metadata": metadata
        }
        
        # ì´ë¯¸ì§€ ì €ì¥
        image_path = os.path.join(self.queue_dir, f"{page_id}_{reason}.png")
        image.save(image_path)
        item["image_path"] = image_path
        
        self.queue.append(item)
    
    def export_queue(self):
        """í ë‚´ë³´ë‚´ê¸°"""
        with open(os.path.join(self.queue_dir, "queue.json"), 'w') as f:
            json.dump(self.queue, f, indent=2)

# ì‚¬ìš© ì˜ˆ
review_queue = ManualReviewQueue()

if ocr_confidence < 0.4:
    review_queue.add_to_queue(page.id, "low_ocr_confidence", 
                               page.image, {"confidence": ocr_confidence})
```

---

### ì¬ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (re-processing pipeline)

**ìš°ì„ ìˆœìœ„**: âšª LOW

**ID**: `post-12`

**ë¬¸ì œì **:
ì¼ë¶€ë§Œ ìˆ˜ì •í•˜ê³  ì‹¶ì€ë° ì „ì²´ ì¬ì‹¤í–‰ í•„ìš”. ì‹œê°„ ë‚­ë¹„.

**í•´ê²°ì±…**:
ìºì‹œ ì‹œìŠ¤í…œ. Stageë³„ ì¤‘ê°„ ê²°ê³¼ ì €ì¥. íŠ¹ì • stageë¶€í„° ì¬ì‹œì‘ ê°€ëŠ¥

**êµ¬í˜„ ì½”ë“œ**:

```python
import pickle

class CachedPipeline:
    def __init__(self, cache_dir="./cache"):
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)
    
    def save_cache(self, stage_num, data):
        """ì¤‘ê°„ ê²°ê³¼ ìºì‹œ"""
        cache_file = os.path.join(self.cache_dir, f"stage_{stage_num}.pkl")
        with open(cache_file, 'wb') as f:
            pickle.dump(data, f)
    
    def load_cache(self, stage_num):
        """ìºì‹œ ë¡œë“œ"""
        cache_file = os.path.join(self.cache_dir, f"stage_{stage_num}.pkl")
        if os.path.exists(cache_file):
            with open(cache_file, 'rb') as f:
                return pickle.load(f)
        return None
    
    def run_from_stage(self, start_stage, input_data):
        """íŠ¹ì • stageë¶€í„° ì¬ì‹œì‘"""
        # ì´ì „ stage ê²°ê³¼ ë¡œë“œ
        if start_stage > 1:
            cached_data = self.load_cache(start_stage - 1)
            if cached_data:
                print(f"Loaded cache from stage {start_stage - 1}")
                input_data = cached_data
        
        # start_stageë¶€í„° ì‹¤í–‰
        for stage_num in range(start_stage, 10):
            result = self.run_stage(stage_num, input_data)
            self.save_cache(stage_num, result)
            input_data = result
        
        return input_data
```

---

